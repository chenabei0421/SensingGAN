{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "Namespace(angle_aug=False, b1=0.5, b2=0.999, baseroot='../rainy_image_dataset/raindrop/train/', crop_size=256, cudnn_benchmark=True, epochs=200, geometry_aug=False, gpu_ids='0, 1, 2, 3', init_gain=0.02, init_type='xavier', load_dname='', load_gname='', lr=0.0001, lr_decrease_epoch=50, mu=0, multi_gpu=False, no_gpu=False, num_workers=1, rainaug=False, raincover=False, raincover_number=2, sample_path='../samples/models_TinyDerainGAN_lr0001_raindrop', save_by_epoch=50, save_by_iter=100000, save_mode='epoch', save_path='../models/models_TinyDerainGAN_lr0001_raindrop', scale_max=1, scale_min=1, sigma=30, train_batch_size=4, weight_decay=0)\n",
      "initialize network with xavier type\n",
      "Generator are created!\n",
      "initialize network with xavier type\n",
      "Discriminator are created!\n",
      "pretrained models loaded\n",
      "There are 1 GPUs used\n",
      "The overall number of training images: 861\n",
      "[Epoch 0/200] [Batch 0/216] [Loss: 0.7069 0.3583 0.0124 0.5049 1.3901] Time_left: 2 days, 14:47:10.253220\n",
      "[Epoch 0/200] [Batch 1/216] [Loss: 0.7260 0.4493 0.0000 0.6221 1.2882] Time_left: 6:05:32.666421\n",
      "[Epoch 0/200] [Batch 2/216] [Loss: 0.7190 0.4784 0.0020 0.4901 0.9517] Time_left: 5:54:59.437301\n",
      "[Epoch 0/200] [Batch 3/216] [Loss: 0.5663 0.5319 -0.0006 0.4904 0.6006] Time_left: 5:53:12.761882\n",
      "[Epoch 0/200] [Batch 4/216] [Loss: 0.2623 0.5526 0.0027 0.3068 0.2834] Time_left: 5:56:31.973927\n",
      "[Epoch 0/200] [Batch 5/216] [Loss: 0.0402 0.7402 -0.0011 0.4246 0.0404] Time_left: 6:31:11.021993\n",
      "[Epoch 0/200] [Batch 6/216] [Loss: 0.0030 0.4856 -0.0034 0.6995 0.0036] Time_left: 13:43:07.564483\n",
      "[Epoch 0/200] [Batch 7/216] [Loss: 0.0006 0.4156 -0.0047 0.4339 0.1119] Time_left: 14:58:57.834203\n",
      "[Epoch 0/200] [Batch 8/216] [Loss: 0.0176 0.5250 -0.0061 0.5339 0.0176] Time_left: 16:19:36.745771\n",
      "[Epoch 0/200] [Batch 9/216] [Loss: 0.1104 0.4017 -0.0123 0.7771 0.1104] Time_left: 19:39:34.507381\n",
      "[Epoch 0/200] [Batch 10/216] [Loss: 0.0026 0.3371 -0.0191 0.5200 0.0061] Time_left: 16:25:30.743134\n",
      "[Epoch 0/200] [Batch 11/216] [Loss: 0.0009 0.5725 -0.0194 0.4026 0.0009] Time_left: 6:55:19.245628\n",
      "[Epoch 0/200] [Batch 12/216] [Loss: 0.0006 0.4230 -0.0335 0.5612 0.0006] Time_left: 13:23:03.039639\n",
      "[Epoch 0/200] [Batch 13/216] [Loss: 0.0005 0.3768 -0.0592 0.5779 0.0005] Time_left: 20:47:10.706533\n",
      "[Epoch 0/200] [Batch 14/216] [Loss: 0.0005 0.5829 -0.0432 0.4239 0.0005] Time_left: 12:24:29.744465\n",
      "[Epoch 0/200] [Batch 15/216] [Loss: 0.0006 0.3857 -0.0759 0.5458 0.0006] Time_left: 16:00:37.129662\n",
      "[Epoch 0/200] [Batch 16/216] [Loss: 0.0006 0.3821 -0.0644 0.6368 0.0006] Time_left: 11:07:01.171150\n",
      "[Epoch 0/200] [Batch 17/216] [Loss: 0.0009 0.3914 -0.0903 0.6509 0.0009] Time_left: 15:45:13.433926\n",
      "[Epoch 0/200] [Batch 18/216] [Loss: 0.0019 0.3891 -0.1326 0.6296 0.0019] Time_left: 5:59:28.483980\n",
      "[Epoch 0/200] [Batch 19/216] [Loss: 0.3786 0.4442 -0.2558 0.3272 0.3786] Time_left: 5:54:03.470994\n",
      "[Epoch 0/200] [Batch 20/216] [Loss: 0.0000 0.1983 -0.3172 0.5426 5.9536] Time_left: 5:56:27.838769\n",
      "[Epoch 0/200] [Batch 21/216] [Loss: 5.3391 0.2343 -0.4089 0.4539 5.7094] Time_left: 5:56:24.069744\n",
      "[Epoch 0/200] [Batch 22/216] [Loss: 3.2341 0.2382 -0.3107 0.6087 3.3605] Time_left: 5:54:53.765830\n",
      "[Epoch 0/200] [Batch 23/216] [Loss: 0.6390 0.1699 -0.3669 0.5495 1.4019] Time_left: 5:55:08.302198\n",
      "[Epoch 0/200] [Batch 24/216] [Loss: 0.5859 0.2019 -0.4105 0.4650 1.5156] Time_left: 7:36:45.034767\n",
      "[Epoch 0/200] [Batch 25/216] [Loss: 0.6241 0.1762 -0.4699 0.4352 1.4173] Time_left: 5:55:11.381197\n",
      "[Epoch 0/200] [Batch 26/216] [Loss: 0.6488 0.1630 -0.4490 0.4612 1.3911] Time_left: 5:59:31.590655\n",
      "[Epoch 0/200] [Batch 27/216] [Loss: 0.6576 0.1805 -0.3711 0.6473 1.3883] Time_left: 5:54:08.768328\n",
      "[Epoch 0/200] [Batch 28/216] [Loss: 0.6686 0.2034 -0.3334 0.7207 1.3836] Time_left: 10:31:22.681081\n",
      "[Epoch 0/200] [Batch 29/216] [Loss: 0.6439 0.1378 -0.4087 0.5279 1.3766] Time_left: 5:54:55.768860\n",
      "[Epoch 0/200] [Batch 30/216] [Loss: 0.6338 0.1625 -0.4065 0.6127 1.3747] Time_left: 5:55:37.742550\n",
      "[Epoch 0/200] [Batch 31/216] [Loss: 0.6592 0.1465 -0.3810 0.4201 1.3928] Time_left: 5:54:58.374292\n",
      "[Epoch 0/200] [Batch 32/216] [Loss: 0.6280 0.2126 -0.4463 0.4931 1.4131] Time_left: 5:57:48.502579\n",
      "[Epoch 0/200] [Batch 33/216] [Loss: 0.6391 0.1427 -0.4426 0.5137 1.3850] Time_left: 6:20:12.877862\n",
      "[Epoch 0/200] [Batch 34/216] [Loss: 0.6617 0.1361 -0.4043 0.4010 1.3700] Time_left: 5:56:40.128979\n",
      "[Epoch 0/200] [Batch 35/216] [Loss: 0.6666 0.1487 -0.4687 0.4564 1.3680] Time_left: 5:57:07.584490\n",
      "[Epoch 0/200] [Batch 36/216] [Loss: 0.6564 0.1226 -0.3415 0.5267 1.3726] Time_left: 5:56:49.510880\n",
      "[Epoch 0/200] [Batch 37/216] [Loss: 0.6497 0.1405 -0.3831 0.7080 1.3763] Time_left: 6:03:50.435931\n",
      "[Epoch 0/200] [Batch 38/216] [Loss: 0.6695 0.1880 -0.5665 0.2216 1.3650] Time_left: 5:57:41.422964\n",
      "[Epoch 0/200] [Batch 39/216] [Loss: 0.6702 0.1578 -0.4574 0.4740 1.3635] Time_left: 5:55:02.484688\n",
      "[Epoch 0/200] [Batch 40/216] [Loss: 0.6895 0.1365 -0.4224 0.4110 1.3311] Time_left: 5:56:37.782097\n",
      "[Epoch 0/200] [Batch 41/216] [Loss: 0.6563 0.1338 -0.4722 0.3851 1.3355] Time_left: 5:58:10.358532\n",
      "[Epoch 0/200] [Batch 42/216] [Loss: 0.6363 0.1294 -0.4993 0.5244 1.3354] Time_left: 6:18:48.921963\n",
      "[Epoch 0/200] [Batch 43/216] [Loss: 0.6264 0.1905 -0.6709 0.2258 1.3859] Time_left: 5:54:33.541855\n",
      "[Epoch 0/200] [Batch 44/216] [Loss: 0.6640 0.1403 -0.3977 0.6006 1.3080] Time_left: 5:58:06.508503\n",
      "[Epoch 0/200] [Batch 45/216] [Loss: 0.6748 0.1305 -0.4727 0.5001 1.2666] Time_left: 5:58:36.476215\n",
      "[Epoch 0/200] [Batch 46/216] [Loss: 0.6427 0.1428 -0.4591 0.4937 1.2894] Time_left: 5:56:55.703809\n",
      "[Epoch 0/200] [Batch 47/216] [Loss: 0.6198 0.1280 -0.4557 0.4149 1.3193] Time_left: 5:59:08.021496\n",
      "[Epoch 0/200] [Batch 48/216] [Loss: 0.6119 0.1365 -0.4191 0.5469 1.1492] Time_left: 9:01:52.119770\n",
      "[Epoch 0/200] [Batch 49/216] [Loss: 0.6618 0.0997 -0.5253 0.3646 1.2031] Time_left: 5:58:50.027040\n",
      "[Epoch 0/200] [Batch 50/216] [Loss: 0.5648 0.1133 -0.5014 0.3973 1.0643] Time_left: 5:57:33.131175\n",
      "[Epoch 0/200] [Batch 51/216] [Loss: 0.4453 0.1983 -0.4643 0.5444 1.3662] Time_left: 5:58:22.600500\n",
      "[Epoch 0/200] [Batch 52/216] [Loss: 0.6415 0.1342 -0.4703 0.4819 1.2027] Time_left: 7:51:21.638916\n",
      "[Epoch 0/200] [Batch 53/216] [Loss: 0.8535 0.1401 -0.4321 0.6519 1.1393] Time_left: 5:56:32.941761\n",
      "[Epoch 0/200] [Batch 54/216] [Loss: 0.5517 0.1353 -0.4401 0.6450 1.3028] Time_left: 5:57:18.026792\n",
      "[Epoch 0/200] [Batch 55/216] [Loss: 0.5543 0.1108 -0.5859 0.3873 1.0752] Time_left: 5:59:18.602844\n",
      "[Epoch 0/200] [Batch 56/216] [Loss: 0.5428 0.1137 -0.3869 0.5712 1.1366] Time_left: 6:04:02.890532\n",
      "[Epoch 0/200] [Batch 57/216] [Loss: 0.5201 0.1444 -0.3295 0.7304 1.0851] Time_left: 5:59:33.608649\n",
      "[Epoch 0/200] [Batch 58/216] [Loss: 1.4168 0.1366 -0.4761 0.5345 1.6419] Time_left: 5:59:27.996531\n",
      "[Epoch 0/200] [Batch 59/216] [Loss: 0.3630 0.1458 -0.5747 0.3485 1.4707] Time_left: 6:00:47.333551\n",
      "[Epoch 0/200] [Batch 60/216] [Loss: 0.5440 0.1400 -0.4157 0.5670 1.1594] Time_left: 7:13:42.169647\n",
      "[Epoch 0/200] [Batch 61/216] [Loss: 0.5934 0.1170 -0.5062 0.4839 1.2316] Time_left: 5:58:00.914097\n",
      "[Epoch 0/200] [Batch 62/216] [Loss: 0.6061 0.1281 -0.4303 0.5158 1.1965] Time_left: 6:00:36.695216\n",
      "[Epoch 0/200] [Batch 63/216] [Loss: 0.5976 0.1134 -0.5550 0.3821 1.3944] Time_left: 5:59:18.071352\n",
      "[Epoch 0/200] [Batch 64/216] [Loss: 0.5995 0.0930 -0.5285 0.4263 1.3240] Time_left: 10:04:17.725922\n",
      "[Epoch 0/200] [Batch 65/216] [Loss: 0.6016 0.1130 -0.4519 0.5054 1.0318] Time_left: 6:00:31.066550\n",
      "[Epoch 0/200] [Batch 66/216] [Loss: 0.5864 0.1161 -0.5512 0.3977 0.9989] Time_left: 6:00:41.003283\n",
      "[Epoch 0/200] [Batch 67/216] [Loss: 0.5901 0.1144 -0.5666 0.3469 1.0444] Time_left: 6:03:12.710737\n",
      "[Epoch 0/200] [Batch 68/216] [Loss: 0.5310 0.1499 -0.5228 0.3776 0.9442] Time_left: 5:56:49.279915\n",
      "[Epoch 0/200] [Batch 69/216] [Loss: 0.6765 0.1298 -0.4247 0.5453 0.9382] Time_left: 6:01:01.730483\n",
      "[Epoch 0/200] [Batch 70/216] [Loss: 0.4363 0.1515 -0.4322 0.5593 1.0391] Time_left: 5:59:58.039258\n",
      "[Epoch 0/200] [Batch 71/216] [Loss: 0.3590 0.2324 -0.6744 0.2604 1.5023] Time_left: 6:01:33.929036\n",
      "[Epoch 0/200] [Batch 72/216] [Loss: 0.6267 0.1149 -0.4029 0.6146 0.9623] Time_left: 6:01:06.434429\n",
      "[Epoch 0/200] [Batch 73/216] [Loss: 0.6648 0.1078 -0.4860 0.4300 0.8781] Time_left: 6:01:03.567130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 74/216] [Loss: 0.6127 0.1065 -0.4497 0.4479 0.9323] Time_left: 6:02:53.535044\n",
      "[Epoch 0/200] [Batch 75/216] [Loss: 1.0359 0.1060 -0.4707 0.4651 1.4581] Time_left: 6:01:13.163027\n",
      "[Epoch 0/200] [Batch 76/216] [Loss: 0.3156 0.1599 -0.3318 0.8157 1.1073] Time_left: 6:01:05.998008\n",
      "[Epoch 0/200] [Batch 77/216] [Loss: 1.1157 0.1197 -0.4165 0.4521 1.6590] Time_left: 6:02:16.539548\n",
      "[Epoch 0/200] [Batch 78/216] [Loss: 0.4780 0.1344 -0.5604 0.3811 1.2387] Time_left: 6:01:18.410002\n",
      "[Epoch 0/200] [Batch 79/216] [Loss: 0.6137 0.1845 -0.4869 0.5622 1.3142] Time_left: 10:06:22.099767\n",
      "[Epoch 0/200] [Batch 80/216] [Loss: 0.6539 0.1203 -0.5646 0.3111 1.3746] Time_left: 6:02:11.151581\n",
      "[Epoch 0/200] [Batch 81/216] [Loss: 0.7233 0.1808 -0.4551 0.4682 1.5042] Time_left: 5:56:25.545847\n",
      "[Epoch 0/200] [Batch 82/216] [Loss: 0.7445 0.0877 -0.6294 0.3525 1.3974] Time_left: 6:06:22.294727\n",
      "[Epoch 0/200] [Batch 83/216] [Loss: 0.7111 0.1173 -0.6069 0.3212 1.2693] Time_left: 6:01:03.889472\n",
      "[Epoch 0/200] [Batch 84/216] [Loss: 0.7330 0.1609 -0.5588 0.4160 1.3823] Time_left: 6:02:21.718002\n",
      "[Epoch 0/200] [Batch 85/216] [Loss: 0.7086 0.1202 -0.4251 0.5373 1.3803] Time_left: 6:02:04.766674\n",
      "[Epoch 0/200] [Batch 86/216] [Loss: 0.6898 0.1437 -0.3288 0.7281 1.1780] Time_left: 5:59:33.138310\n",
      "[Epoch 0/200] [Batch 87/216] [Loss: 0.6824 0.1479 -0.5048 0.5352 1.3457] Time_left: 6:03:26.082947\n",
      "[Epoch 0/200] [Batch 88/216] [Loss: 0.6569 0.1144 -0.5039 0.3862 1.1361] Time_left: 8:11:55.641644\n",
      "[Epoch 0/200] [Batch 89/216] [Loss: 0.7026 0.1445 -0.5724 0.3298 1.2056] Time_left: 6:00:57.924887\n",
      "[Epoch 0/200] [Batch 90/216] [Loss: 0.6358 0.1302 -0.4414 0.5367 1.0842] Time_left: 6:01:41.618879\n",
      "[Epoch 0/200] [Batch 91/216] [Loss: 0.6245 0.1032 -0.5158 0.4845 1.2942] Time_left: 6:05:26.398664\n",
      "[Epoch 0/200] [Batch 92/216] [Loss: 0.5624 0.1030 -0.5508 0.4321 1.0488] Time_left: 6:02:42.864397\n",
      "[Epoch 0/200] [Batch 93/216] [Loss: 0.5451 0.1151 -0.5291 0.4893 1.0146] Time_left: 6:01:50.828118\n",
      "[Epoch 0/200] [Batch 94/216] [Loss: 0.5739 0.1159 -0.5129 0.5087 1.1089] Time_left: 6:01:41.249638\n",
      "[Epoch 0/200] [Batch 95/216] [Loss: 7.1937 0.1517 -0.4747 0.4509 7.1939] Time_left: 6:02:14.557637\n",
      "[Epoch 0/200] [Batch 96/216] [Loss: 0.2596 0.1055 -0.3985 0.6494 1.5535] Time_left: 9:19:23.301521\n",
      "[Epoch 0/200] [Batch 97/216] [Loss: 0.3708 0.1245 -0.4783 0.4668 1.1762] Time_left: 6:08:41.376137\n",
      "[Epoch 0/200] [Batch 98/216] [Loss: 0.4638 0.1207 -0.5474 0.4420 1.3751] Time_left: 6:03:27.928493\n",
      "[Epoch 0/200] [Batch 99/216] [Loss: 0.5413 0.0932 -0.6065 0.3528 1.3512] Time_left: 6:00:18.239914\n",
      "[Epoch 0/200] [Batch 100/216] [Loss: 0.5841 0.0830 -0.6486 0.2578 1.1980] Time_left: 6:04:34.110293\n",
      "[Epoch 0/200] [Batch 101/216] [Loss: 0.6019 0.0854 -0.6114 0.3722 1.2048] Time_left: 6:08:43.217705\n",
      "[Epoch 0/200] [Batch 102/216] [Loss: 0.6070 0.1069 -0.4751 0.4868 1.2817] Time_left: 6:03:55.621001\n",
      "[Epoch 0/200] [Batch 103/216] [Loss: 0.5946 0.0997 -0.5711 0.3547 1.0678] Time_left: 6:04:34.057076\n",
      "[Epoch 0/200] [Batch 104/216] [Loss: 0.5984 0.1687 -0.5350 0.4544 1.1610] Time_left: 6:02:35.234198\n",
      "[Epoch 0/200] [Batch 105/216] [Loss: 0.5762 0.1247 -0.4759 0.4992 1.2834] Time_left: 6:05:33.878163\n",
      "[Epoch 0/200] [Batch 106/216] [Loss: 0.5925 0.1229 -0.4866 0.5516 1.2327] Time_left: 6:10:43.194038\n",
      "[Epoch 0/200] [Batch 107/216] [Loss: 0.5809 0.1323 -0.4169 0.6367 1.1099] Time_left: 6:03:52.882266\n",
      "[Epoch 0/200] [Batch 108/216] [Loss: 0.5915 0.1431 -0.3907 0.7355 1.0222] Time_left: 6:05:10.632171\n",
      "[Epoch 0/200] [Batch 109/216] [Loss: 0.5360 0.1238 -0.3798 0.6823 1.2019] Time_left: 6:02:38.196307\n",
      "[Epoch 0/200] [Batch 110/216] [Loss: 0.6771 0.1110 -0.5685 0.3910 1.1068] Time_left: 11:05:53.996561\n",
      "[Epoch 0/200] [Batch 111/216] [Loss: 0.8365 0.1171 -0.5516 0.4684 1.1037] Time_left: 6:06:08.609265\n",
      "[Epoch 0/200] [Batch 112/216] [Loss: 0.4801 0.1124 -0.5967 0.3826 1.1200] Time_left: 6:04:45.124565\n",
      "[Epoch 0/200] [Batch 113/216] [Loss: 0.4610 0.1195 -0.4445 0.4877 1.3412] Time_left: 6:06:47.190998\n",
      "[Epoch 0/200] [Batch 114/216] [Loss: 0.5695 0.1118 -0.5202 0.4971 1.2407] Time_left: 6:05:18.038808\n",
      "[Epoch 0/200] [Batch 115/216] [Loss: 0.5032 0.0964 -0.5510 0.3977 1.1152] Time_left: 6:05:35.434661\n",
      "[Epoch 0/200] [Batch 116/216] [Loss: 0.5260 0.1137 -0.3939 0.6250 1.2254] Time_left: 7:55:40.670333\n",
      "[Epoch 0/200] [Batch 117/216] [Loss: 0.5536 0.0782 -0.6384 0.3301 1.1898] Time_left: 6:06:54.926692\n",
      "[Epoch 0/200] [Batch 118/216] [Loss: 0.5830 0.0980 -0.5184 0.4464 1.2425] Time_left: 6:03:02.206790\n",
      "[Epoch 0/200] [Batch 119/216] [Loss: 0.6965 0.1404 -0.4928 0.5360 0.9072] Time_left: 6:08:15.838961\n",
      "[Epoch 0/200] [Batch 120/216] [Loss: 0.6078 0.1261 -0.6216 0.3941 0.9492] Time_left: 6:07:06.674223\n",
      "[Epoch 0/200] [Batch 121/216] [Loss: 0.5676 0.0961 -0.5314 0.5376 0.8413] Time_left: 6:01:58.592532\n",
      "[Epoch 0/200] [Batch 122/216] [Loss: 0.3724 0.0759 -0.6597 0.2631 1.5063] Time_left: 6:06:24.086529\n",
      "[Epoch 0/200] [Batch 123/216] [Loss: 1.1241 0.0937 -0.5400 0.4251 1.5425] Time_left: 11:33:48.181260\n",
      "[Epoch 0/200] [Batch 124/216] [Loss: 0.3978 0.0832 -0.5926 0.3350 1.3201] Time_left: 6:02:18.883522\n",
      "[Epoch 0/200] [Batch 125/216] [Loss: 0.4672 0.1299 -0.4794 0.4810 0.8805] Time_left: 6:07:20.754944\n",
      "[Epoch 0/200] [Batch 126/216] [Loss: 0.4654 0.1076 -0.5492 0.4465 1.1183] Time_left: 6:03:44.549973\n",
      "[Epoch 0/200] [Batch 127/216] [Loss: 0.4611 0.1049 -0.4782 0.4922 0.9780] Time_left: 6:07:03.331340\n",
      "[Epoch 0/200] [Batch 128/216] [Loss: 0.9054 0.1345 -0.3533 0.6536 1.4375] Time_left: 6:07:00.735397\n",
      "[Epoch 0/200] [Batch 129/216] [Loss: 0.4788 0.1007 -0.5616 0.4680 0.9859] Time_left: 6:01:44.372498\n",
      "[Epoch 0/200] [Batch 130/216] [Loss: 0.5075 0.0955 -0.5780 0.3786 0.9978] Time_left: 15:26:03.676755\n",
      "[Epoch 0/200] [Batch 131/216] [Loss: 0.4664 0.0961 -0.5543 0.5095 0.9162] Time_left: 6:06:57.702441\n",
      "[Epoch 0/200] [Batch 132/216] [Loss: 0.4531 0.1030 -0.5065 0.5480 1.1892] Time_left: 5:58:58.846596\n",
      "[Epoch 0/200] [Batch 133/216] [Loss: 0.4788 0.1275 -0.5534 0.4054 0.7767] Time_left: 6:09:25.206232\n",
      "[Epoch 0/200] [Batch 134/216] [Loss: 0.4760 0.0922 -0.6119 0.3733 1.3129] Time_left: 6:14:59.727741\n",
      "[Epoch 0/200] [Batch 135/216] [Loss: 0.5322 0.1271 -0.3881 0.5926 0.7674] Time_left: 6:08:45.509505\n",
      "[Epoch 0/200] [Batch 136/216] [Loss: 0.7577 0.1376 -0.4100 0.6086 0.8886] Time_left: 6:04:37.544558\n",
      "[Epoch 0/200] [Batch 137/216] [Loss: 0.2638 0.1037 -0.5866 0.3741 0.9580] Time_left: 6:06:36.626774\n",
      "[Epoch 0/200] [Batch 138/216] [Loss: 0.3805 0.1003 -0.5299 0.4842 0.8648] Time_left: 6:13:01.736262\n",
      "[Epoch 0/200] [Batch 139/216] [Loss: 0.4655 0.1016 -0.5458 0.4341 1.1792] Time_left: 6:05:56.458846\n",
      "[Epoch 0/200] [Batch 140/216] [Loss: 0.3584 0.1110 -0.5935 0.4022 1.1752] Time_left: 6:04:25.564413\n",
      "[Epoch 0/200] [Batch 141/216] [Loss: 0.4683 0.0965 -0.5089 0.4761 1.0574] Time_left: 10:21:18.157930\n",
      "[Epoch 0/200] [Batch 142/216] [Loss: 0.6518 0.1267 -0.4736 0.4416 1.0710] Time_left: 6:07:31.427945\n",
      "[Epoch 0/200] [Batch 143/216] [Loss: 0.5147 0.1113 -0.4907 0.6363 0.9737] Time_left: 6:06:14.355051\n",
      "[Epoch 0/200] [Batch 144/216] [Loss: 0.7735 0.0847 -0.6818 0.3146 0.9681] Time_left: 6:00:06.950809\n",
      "[Epoch 0/200] [Batch 145/216] [Loss: 0.3911 0.0945 -0.4805 0.5008 1.0680] Time_left: 6:04:34.501843\n",
      "[Epoch 0/200] [Batch 146/216] [Loss: 0.3655 0.1048 -0.5216 0.4353 0.8188] Time_left: 6:06:22.349789\n",
      "[Epoch 0/200] [Batch 147/216] [Loss: 0.3375 0.1035 -0.4760 0.5295 0.9005] Time_left: 6:05:00.882035\n",
      "[Epoch 0/200] [Batch 148/216] [Loss: 0.4673 0.1173 -0.4802 0.5914 1.0270] Time_left: 6:06:12.388347\n",
      "[Epoch 0/200] [Batch 149/216] [Loss: 1.0611 0.1157 -0.4119 0.5842 1.2383] Time_left: 6:04:49.969995\n",
      "[Epoch 0/200] [Batch 150/216] [Loss: 0.2503 0.1160 -0.5315 0.4647 0.4424] Time_left: 6:08:16.033180\n",
      "[Epoch 0/200] [Batch 151/216] [Loss: 0.2539 0.1089 -0.4901 0.5741 0.8532] Time_left: 6:04:19.906845\n",
      "[Epoch 0/200] [Batch 152/216] [Loss: 0.1849 0.1122 -0.7284 0.2165 1.7141] Time_left: 6:04:07.329245\n",
      "[Epoch 0/200] [Batch 153/216] [Loss: 0.6529 0.0886 -0.6756 0.2643 1.1774] Time_left: 12:11:48.452339\n",
      "[Epoch 0/200] [Batch 154/216] [Loss: 0.6438 0.1066 -0.4564 0.5380 1.0163] Time_left: 6:05:11.832999\n",
      "[Epoch 0/200] [Batch 155/216] [Loss: 0.6560 0.1115 -0.5384 0.5054 0.8431] Time_left: 6:05:22.089567\n",
      "[Epoch 0/200] [Batch 156/216] [Loss: 0.6295 0.0890 -0.5849 0.3839 1.0661] Time_left: 6:06:33.417709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 157/216] [Loss: 0.5993 0.1178 -0.5107 0.4015 1.3211] Time_left: 6:05:20.321857\n",
      "[Epoch 0/200] [Batch 158/216] [Loss: 0.6068 0.1354 -0.5513 0.4379 0.8178] Time_left: 6:05:18.324599\n",
      "[Epoch 0/200] [Batch 159/216] [Loss: 0.8218 0.1109 -0.6242 0.4790 1.1106] Time_left: 6:05:41.756087\n",
      "[Epoch 0/200] [Batch 160/216] [Loss: 0.5060 0.0978 -0.5446 0.5271 1.0052] Time_left: 6:04:25.813751\n",
      "[Epoch 0/200] [Batch 161/216] [Loss: 0.4701 0.1144 -0.5256 0.4973 0.9929] Time_left: 6:04:54.447801\n",
      "[Epoch 0/200] [Batch 162/216] [Loss: 0.4076 0.1410 -0.4210 0.5159 0.4263] Time_left: 6:05:11.495760\n",
      "[Epoch 0/200] [Batch 163/216] [Loss: 0.3655 0.1162 -0.5234 0.5176 1.0303] Time_left: 6:05:05.497102\n",
      "[Epoch 0/200] [Batch 164/216] [Loss: 0.3855 0.1572 -0.5539 0.4683 1.2085] Time_left: 6:08:32.323689\n",
      "[Epoch 0/200] [Batch 165/216] [Loss: 0.3174 0.1071 -0.5502 0.4056 1.2768] Time_left: 6:09:49.962916\n",
      "[Epoch 0/200] [Batch 166/216] [Loss: 0.4032 0.1140 -0.4654 0.5807 0.9342] Time_left: 6:11:19.418152\n",
      "[Epoch 0/200] [Batch 167/216] [Loss: 0.5073 0.1154 -0.5456 0.5113 0.8391] Time_left: 6:08:36.979219\n",
      "[Epoch 0/200] [Batch 168/216] [Loss: 0.4906 0.0895 -0.6218 0.3730 1.0845] Time_left: 6:08:01.962135\n",
      "[Epoch 0/200] [Batch 169/216] [Loss: 0.6783 0.0799 -0.6541 0.3150 1.0978] Time_left: 6:07:57.499118\n",
      "[Epoch 0/200] [Batch 170/216] [Loss: 7.5219 0.1030 -0.4879 0.4990 7.6278] Time_left: 6:08:19.607487\n",
      "[Epoch 0/200] [Batch 171/216] [Loss: 0.3893 0.1252 -0.4862 0.6071 0.5218] Time_left: 6:07:45.937094\n",
      "[Epoch 0/200] [Batch 172/216] [Loss: 0.6290 0.1044 -0.6046 0.3658 1.0903] Time_left: 6:08:23.801980\n",
      "[Epoch 0/200] [Batch 173/216] [Loss: 0.1496 0.1048 -0.4995 0.5193 1.1363] Time_left: 6:07:31.934541\n",
      "[Epoch 0/200] [Batch 174/216] [Loss: 0.2606 0.1182 -0.5104 0.6211 0.9267] Time_left: 6:08:28.960258\n",
      "[Epoch 0/200] [Batch 175/216] [Loss: 0.6471 0.1024 -0.4670 0.5018 0.8359] Time_left: 6:09:39.749483\n",
      "[Epoch 0/200] [Batch 176/216] [Loss: 0.4351 0.1120 -0.5890 0.3514 0.9949] Time_left: 6:06:49.981579\n",
      "[Epoch 0/200] [Batch 177/216] [Loss: 0.3941 0.0900 -0.6498 0.3571 1.1739] Time_left: 6:08:44.240976\n",
      "[Epoch 0/200] [Batch 178/216] [Loss: 0.5045 0.1279 -0.5172 0.4761 0.9548] Time_left: 6:09:52.173324\n",
      "[Epoch 0/200] [Batch 179/216] [Loss: 2.2410 0.0990 -0.5273 0.4393 2.2443] Time_left: 6:01:08.068121\n",
      "[Epoch 0/200] [Batch 180/216] [Loss: 0.3621 0.1205 -0.4722 0.5617 1.0330] Time_left: 6:06:36.119485\n",
      "[Epoch 0/200] [Batch 181/216] [Loss: 0.3452 0.0982 -0.5786 0.4212 1.2559] Time_left: 6:07:40.101238\n",
      "[Epoch 0/200] [Batch 182/216] [Loss: 0.4195 0.1050 -0.5018 0.4674 1.4859] Time_left: 6:09:20.920589\n",
      "[Epoch 0/200] [Batch 183/216] [Loss: 0.5094 0.0819 -0.5992 0.3908 1.1834] Time_left: 6:06:51.323462\n",
      "[Epoch 0/200] [Batch 184/216] [Loss: 0.5495 0.1040 -0.5694 0.4172 1.1137] Time_left: 6:11:21.257578\n",
      "[Epoch 0/200] [Batch 185/216] [Loss: 0.9863 0.1044 -0.4862 0.4808 1.6154] Time_left: 6:08:08.334756\n",
      "[Epoch 0/200] [Batch 186/216] [Loss: 0.5685 0.1098 -0.5023 0.5304 1.1728] Time_left: 6:14:43.226017\n",
      "[Epoch 0/200] [Batch 187/216] [Loss: 0.5576 0.1094 -0.4909 0.5174 1.3714] Time_left: 6:08:25.602845\n",
      "[Epoch 0/200] [Batch 188/216] [Loss: 0.5426 0.1094 -0.5896 0.4288 0.9847] Time_left: 6:05:00.053247\n",
      "[Epoch 0/200] [Batch 189/216] [Loss: 0.5665 0.1168 -0.5057 0.5186 1.0182] Time_left: 6:11:43.083951\n",
      "[Epoch 0/200] [Batch 190/216] [Loss: 0.5373 0.1240 -0.5165 0.5766 1.0424] Time_left: 6:11:31.572709\n",
      "[Epoch 0/200] [Batch 191/216] [Loss: 0.5863 0.0920 -0.6716 0.3271 0.9074] Time_left: 6:09:17.689015\n",
      "[Epoch 0/200] [Batch 192/216] [Loss: 0.4380 0.1512 -0.4725 0.5817 0.6543] Time_left: 6:08:58.398926\n",
      "[Epoch 0/200] [Batch 193/216] [Loss: 0.3678 0.1084 -0.4826 0.5350 0.9913] Time_left: 6:12:08.653665\n",
      "[Epoch 0/200] [Batch 194/216] [Loss: 0.3488 0.1211 -0.6051 0.3531 1.3247] Time_left: 6:09:07.387025\n",
      "[Epoch 0/200] [Batch 195/216] [Loss: 0.6484 0.1038 -0.5680 0.3799 1.0471] Time_left: 6:09:23.759047\n",
      "[Epoch 0/200] [Batch 196/216] [Loss: 0.3997 0.1263 -0.4934 0.5088 0.8279] Time_left: 6:09:19.634631\n",
      "[Epoch 0/200] [Batch 197/216] [Loss: 0.3617 0.0798 -0.6164 0.3244 1.2553] Time_left: 6:11:24.335737\n",
      "[Epoch 0/200] [Batch 198/216] [Loss: 0.5028 0.1363 -0.4481 0.5554 0.6082] Time_left: 6:09:10.812165\n",
      "[Epoch 0/200] [Batch 199/216] [Loss: 0.4046 0.1297 -0.5773 0.3605 1.3828] Time_left: 6:08:51.002343\n",
      "[Epoch 0/200] [Batch 200/216] [Loss: 0.6599 0.1237 -0.4696 0.7292 0.6970] Time_left: 6:13:22.729511\n",
      "[Epoch 0/200] [Batch 201/216] [Loss: 0.2293 0.0963 -0.5097 0.5316 0.8560] Time_left: 6:00:35.479351\n",
      "[Epoch 0/200] [Batch 202/216] [Loss: 0.3065 0.1008 -0.5112 0.4421 0.5656] Time_left: 6:08:05.335804\n",
      "[Epoch 0/200] [Batch 203/216] [Loss: 0.3012 0.0989 -0.5477 0.4704 0.6893] Time_left: 6:09:18.313621\n",
      "[Epoch 0/200] [Batch 204/216] [Loss: 0.3828 0.1114 -0.4519 0.4757 0.6407] Time_left: 6:15:39.393434\n",
      "[Epoch 0/200] [Batch 205/216] [Loss: 0.4851 0.0915 -0.5770 0.4129 1.2818] Time_left: 6:11:31.578749\n",
      "[Epoch 0/200] [Batch 206/216] [Loss: 0.5001 0.1065 -0.5478 0.4064 1.0301] Time_left: 6:08:42.797200\n",
      "[Epoch 0/200] [Batch 207/216] [Loss: 0.5244 0.1199 -0.5400 0.6256 0.7179] Time_left: 6:13:23.254440\n",
      "[Epoch 0/200] [Batch 208/216] [Loss: 0.3963 0.0977 -0.5502 0.4521 1.2033] Time_left: 6:08:24.322433\n",
      "[Epoch 0/200] [Batch 209/216] [Loss: 0.3666 0.1195 -0.5724 0.4491 1.5186] Time_left: 6:11:47.657363\n",
      "[Epoch 0/200] [Batch 210/216] [Loss: 0.6886 0.1125 -0.6296 0.3050 1.2042] Time_left: 6:11:04.428327\n",
      "[Epoch 0/200] [Batch 211/216] [Loss: 0.6528 0.0825 -0.6150 0.3012 0.9707] Time_left: 6:08:31.737939\n",
      "[Epoch 0/200] [Batch 212/216] [Loss: 0.6257 0.1389 -0.4548 0.6080 0.8172] Time_left: 6:12:27.322721\n",
      "[Epoch 0/200] [Batch 213/216] [Loss: 0.5989 0.1254 -0.5849 0.3615 1.0827] Time_left: 6:09:29.158697\n",
      "[Epoch 0/200] [Batch 214/216] [Loss: 0.4323 0.0956 -0.6165 0.3322 1.0186] Time_left: 6:07:27.555049\n",
      "[Epoch 0/200] [Batch 215/216] [Loss: 0.4415 0.1379 -0.3927 0.7209 0.5885] Time_left: 1 day, 23:40:50.564048\n",
      "[Epoch 1/200] [Batch 0/216] [Loss: 0.3052 0.1052 -0.5180 0.4002 0.6556] Time_left: 8:29:22.811314\n",
      "[Epoch 1/200] [Batch 1/216] [Loss: 0.3810 0.1565 -0.4792 0.5178 0.9058] Time_left: 6:23:47.380131\n",
      "[Epoch 1/200] [Batch 2/216] [Loss: 0.5596 0.1277 -0.5068 0.4925 1.2953] Time_left: 6:11:01.412392\n",
      "[Epoch 1/200] [Batch 3/216] [Loss: 0.2767 0.1286 -0.5074 0.5280 0.6070] Time_left: 6:10:21.779879\n",
      "[Epoch 1/200] [Batch 4/216] [Loss: 0.1853 0.1172 -0.5968 0.5089 0.7788] Time_left: 6:10:38.232279\n",
      "[Epoch 1/200] [Batch 5/216] [Loss: 1.2416 0.1111 -0.5505 0.4456 1.9991] Time_left: 6:10:53.300545\n",
      "[Epoch 1/200] [Batch 6/216] [Loss: 0.4279 0.1051 -0.6668 0.3470 1.0879] Time_left: 6:10:04.848460\n",
      "[Epoch 1/200] [Batch 7/216] [Loss: 0.4103 0.1106 -0.5749 0.3935 1.3440] Time_left: 6:11:09.653338\n",
      "[Epoch 1/200] [Batch 8/216] [Loss: 0.7703 0.1299 -0.4337 0.5882 1.2361] Time_left: 6:12:20.029152\n",
      "[Epoch 1/200] [Batch 9/216] [Loss: 0.6543 0.0845 -0.6109 0.3414 1.0538] Time_left: 6:08:34.311647\n",
      "[Epoch 1/200] [Batch 10/216] [Loss: 0.8535 0.1316 -0.6141 0.3483 1.1736] Time_left: 6:11:42.750106\n",
      "[Epoch 1/200] [Batch 11/216] [Loss: 0.5693 0.1035 -0.4320 0.5068 1.3439] Time_left: 6:09:07.830510\n",
      "[Epoch 1/200] [Batch 12/216] [Loss: 0.4506 0.1058 -0.5658 0.4768 1.4113] Time_left: 6:14:15.730084\n",
      "[Epoch 1/200] [Batch 13/216] [Loss: 0.5969 0.1233 -0.5971 0.4114 1.3487] Time_left: 6:08:25.153462\n",
      "[Epoch 1/200] [Batch 14/216] [Loss: 0.4317 0.0952 -0.5481 0.5081 1.3978] Time_left: 6:13:25.765810\n",
      "[Epoch 1/200] [Batch 15/216] [Loss: 0.7145 0.0696 -0.6740 0.2384 1.3908] Time_left: 6:08:48.230184\n",
      "[Epoch 1/200] [Batch 16/216] [Loss: 0.6667 0.1124 -0.5265 0.4154 1.3415] Time_left: 6:12:30.130709\n",
      "[Epoch 1/200] [Batch 17/216] [Loss: 0.7215 0.1252 -0.4651 0.5328 1.4097] Time_left: 6:09:34.425665\n",
      "[Epoch 1/200] [Batch 18/216] [Loss: 0.6971 0.1231 -0.6352 0.3658 1.4052] Time_left: 6:03:19.290430\n",
      "[Epoch 1/200] [Batch 19/216] [Loss: 0.5747 0.1080 -0.5725 0.4373 0.9214] Time_left: 6:09:10.683323\n",
      "[Epoch 1/200] [Batch 20/216] [Loss: 0.6713 0.1089 -0.5481 0.4403 1.3309] Time_left: 6:09:17.082077\n",
      "[Epoch 1/200] [Batch 21/216] [Loss: 0.6248 0.1016 -0.6569 0.2939 1.3535] Time_left: 6:15:55.363991\n",
      "[Epoch 1/200] [Batch 22/216] [Loss: 0.7098 0.1116 -0.5785 0.4983 1.1223] Time_left: 6:12:14.072931\n",
      "[Epoch 1/200] [Batch 23/216] [Loss: 0.6700 0.1395 -0.4728 0.5802 0.9917] Time_left: 6:09:24.886524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 24/216] [Loss: 0.7753 0.1020 -0.5184 0.4593 1.0259] Time_left: 6:14:19.097443\n",
      "[Epoch 1/200] [Batch 25/216] [Loss: 0.4559 0.1180 -0.5334 0.4125 0.6477] Time_left: 6:10:23.566828\n",
      "[Epoch 1/200] [Batch 26/216] [Loss: 0.2696 0.0997 -0.5582 0.3808 1.1203] Time_left: 6:10:17.846579\n",
      "[Epoch 1/200] [Batch 27/216] [Loss: 0.3745 0.1057 -0.6423 0.3727 0.8129] Time_left: 6:15:20.485088\n",
      "[Epoch 1/200] [Batch 28/216] [Loss: 0.3462 0.0985 -0.6831 0.2740 1.4984] Time_left: 6:07:09.218470\n",
      "[Epoch 1/200] [Batch 29/216] [Loss: 0.5285 0.1033 -0.6196 0.3981 0.8480] Time_left: 6:13:54.147278\n",
      "[Epoch 1/200] [Batch 30/216] [Loss: 0.7240 0.0889 -0.5073 0.4574 1.1517] Time_left: 6:08:58.601367\n",
      "[Epoch 1/200] [Batch 31/216] [Loss: 0.4420 0.1407 -0.4478 0.6349 0.5553] Time_left: 6:13:08.289025\n",
      "[Epoch 1/200] [Batch 32/216] [Loss: 0.1759 0.1158 -0.4184 0.5266 1.0195] Time_left: 6:12:24.173756\n",
      "[Epoch 1/200] [Batch 33/216] [Loss: 0.8414 0.1299 -0.5033 0.5901 0.8597] Time_left: 6:09:49.690386\n",
      "[Epoch 1/200] [Batch 34/216] [Loss: 0.0816 0.1102 -0.5104 0.4797 2.2965] Time_left: 6:11:43.432548\n",
      "[Epoch 1/200] [Batch 35/216] [Loss: 0.4614 0.1202 -0.5269 0.4714 0.7805] Time_left: 6:10:03.689214\n",
      "[Epoch 1/200] [Batch 36/216] [Loss: 0.5781 0.0857 -0.6592 0.3153 0.9887] Time_left: 6:13:14.867809\n",
      "[Epoch 1/200] [Batch 37/216] [Loss: 0.6221 0.1067 -0.6507 0.3386 1.3544] Time_left: 6:11:37.307927\n",
      "[Epoch 1/200] [Batch 38/216] [Loss: 0.6422 0.1024 -0.6566 0.3585 1.2974] Time_left: 6:10:38.139041\n",
      "[Epoch 1/200] [Batch 39/216] [Loss: 0.6385 0.0980 -0.6289 0.4122 1.3663] Time_left: 6:11:40.897540\n",
      "[Epoch 1/200] [Batch 40/216] [Loss: 0.6351 0.1101 -0.5492 0.4917 1.0796] Time_left: 6:11:25.153381\n",
      "[Epoch 1/200] [Batch 41/216] [Loss: 0.6582 0.0971 -0.6616 0.3130 1.0801] Time_left: 6:12:40.777494\n",
      "[Epoch 1/200] [Batch 42/216] [Loss: 0.6254 0.0806 -0.7317 0.2642 1.3938] Time_left: 6:13:51.872789\n",
      "[Epoch 1/200] [Batch 43/216] [Loss: 0.6121 0.1168 -0.5408 0.4733 0.8382] Time_left: 6:08:11.799154\n",
      "[Epoch 1/200] [Batch 44/216] [Loss: 0.6121 0.1242 -0.4941 0.4336 1.0247] Time_left: 6:13:54.380517\n",
      "[Epoch 1/200] [Batch 45/216] [Loss: 0.5708 0.1144 -0.4566 0.5493 1.1910] Time_left: 6:09:59.532942\n",
      "[Epoch 1/200] [Batch 46/216] [Loss: 0.5536 0.1040 -0.5019 0.5821 1.0461] Time_left: 6:12:31.611897\n",
      "[Epoch 1/200] [Batch 47/216] [Loss: 0.5498 0.1140 -0.5675 0.4689 1.0621] Time_left: 6:12:45.208134\n",
      "[Epoch 1/200] [Batch 48/216] [Loss: 0.5582 0.1153 -0.4984 0.5126 0.8411] Time_left: 6:10:37.137468\n",
      "[Epoch 1/200] [Batch 49/216] [Loss: 0.7741 0.1025 -0.6248 0.3670 1.0431] Time_left: 6:10:58.013843\n",
      "[Epoch 1/200] [Batch 50/216] [Loss: 0.4497 0.0820 -0.6925 0.2554 1.1559] Time_left: 6:13:16.503887\n",
      "[Epoch 1/200] [Batch 51/216] [Loss: 1.4735 0.1116 -0.5492 0.4166 1.6585] Time_left: 6:10:03.156001\n",
      "[Epoch 1/200] [Batch 52/216] [Loss: 0.4407 0.1117 -0.6573 0.3821 1.4025] Time_left: 6:11:31.434290\n",
      "[Epoch 1/200] [Batch 53/216] [Loss: 0.4704 0.1110 -0.4917 0.5407 1.1742] Time_left: 6:11:13.627223\n",
      "[Epoch 1/200] [Batch 54/216] [Loss: 0.5007 0.1292 -0.5178 0.4389 1.1634] Time_left: 6:14:09.769843\n",
      "[Epoch 1/200] [Batch 55/216] [Loss: 0.4963 0.1239 -0.7060 0.2698 0.9275] Time_left: 6:11:06.499708\n",
      "[Epoch 1/200] [Batch 56/216] [Loss: 0.5190 0.1017 -0.5428 0.4103 1.0376] Time_left: 6:09:36.293186\n",
      "[Epoch 1/200] [Batch 57/216] [Loss: 0.5252 0.0939 -0.5818 0.4644 1.3970] Time_left: 6:13:01.205371\n",
      "[Epoch 1/200] [Batch 58/216] [Loss: 0.4997 0.1016 -0.5554 0.4051 1.0248] Time_left: 6:12:48.853077\n",
      "[Epoch 1/200] [Batch 59/216] [Loss: 0.5588 0.0963 -0.5826 0.3579 1.2007] Time_left: 6:11:32.722315\n",
      "[Epoch 1/200] [Batch 60/216] [Loss: 0.5966 0.1026 -0.5495 0.5228 1.2206] Time_left: 6:11:52.967514\n",
      "[Epoch 1/200] [Batch 61/216] [Loss: 0.6062 0.0867 -0.6079 0.3121 1.0594] Time_left: 6:12:27.804918\n",
      "[Epoch 1/200] [Batch 62/216] [Loss: 0.5689 0.1158 -0.5990 0.3892 1.2293] Time_left: 6:09:55.563847\n",
      "[Epoch 1/200] [Batch 63/216] [Loss: 0.5306 0.0929 -0.6548 0.3771 0.7700] Time_left: 6:13:19.362082\n",
      "[Epoch 1/200] [Batch 64/216] [Loss: 0.5070 0.1027 -0.5984 0.4603 0.8917] Time_left: 6:09:38.934641\n",
      "[Epoch 1/200] [Batch 65/216] [Loss: 0.4559 0.1135 -0.4651 0.5817 1.1457] Time_left: 6:12:38.083409\n",
      "[Epoch 1/200] [Batch 66/216] [Loss: 0.4448 0.0960 -0.6192 0.4150 0.7353] Time_left: 6:13:12.301635\n",
      "[Epoch 1/200] [Batch 67/216] [Loss: 0.4294 0.1006 -0.6576 0.3491 1.3470] Time_left: 6:11:14.784798\n",
      "[Epoch 1/200] [Batch 68/216] [Loss: 0.4711 0.1093 -0.5919 0.4552 0.5827] Time_left: 6:10:42.802464\n",
      "[Epoch 1/200] [Batch 69/216] [Loss: 0.5738 0.1011 -0.7196 0.3366 0.8506] Time_left: 6:14:09.415387\n",
      "[Epoch 1/200] [Batch 70/216] [Loss: 0.5877 0.0944 -0.6005 0.3554 0.8992] Time_left: 6:10:44.937654\n",
      "[Epoch 1/200] [Batch 71/216] [Loss: 0.1888 0.1085 -0.5734 0.4206 0.8502] Time_left: 6:10:53.985518\n",
      "[Epoch 1/200] [Batch 72/216] [Loss: 0.7741 0.1242 -0.6133 0.3421 0.7742] Time_left: 6:12:24.492302\n",
      "[Epoch 1/200] [Batch 73/216] [Loss: 0.1334 0.0869 -0.7184 0.2530 1.4487] Time_left: 6:12:37.875226\n",
      "[Epoch 1/200] [Batch 74/216] [Loss: 0.1784 0.1116 -0.6156 0.3947 0.9385] Time_left: 6:10:29.881654\n",
      "[Epoch 1/200] [Batch 75/216] [Loss: 0.3235 0.1132 -0.7021 0.3725 1.3318] Time_left: 6:13:16.905265\n",
      "[Epoch 1/200] [Batch 76/216] [Loss: 0.3837 0.0908 -0.6487 0.3959 0.6801] Time_left: 6:10:59.965393\n",
      "[Epoch 1/200] [Batch 77/216] [Loss: 0.5519 0.0748 -0.6808 0.3247 0.8363] Time_left: 6:10:25.923470\n",
      "[Epoch 1/200] [Batch 78/216] [Loss: 0.4486 0.0935 -0.6256 0.4252 0.8194] Time_left: 6:13:09.334608\n",
      "[Epoch 1/200] [Batch 79/216] [Loss: 0.5553 0.1016 -0.6250 0.3428 0.8101] Time_left: 6:13:13.722873\n",
      "[Epoch 1/200] [Batch 80/216] [Loss: 0.3293 0.1123 -0.5860 0.5374 0.9098] Time_left: 6:10:15.991821\n",
      "[Epoch 1/200] [Batch 81/216] [Loss: 3.4751 0.1162 -0.6039 0.3465 3.4775] Time_left: 6:11:56.995572\n",
      "[Epoch 1/200] [Batch 82/216] [Loss: 0.1881 0.0863 -0.7329 0.2308 0.9792] Time_left: 6:12:08.964561\n",
      "[Epoch 1/200] [Batch 83/216] [Loss: 0.2260 0.1014 -0.6000 0.4624 0.9581] Time_left: 6:10:34.792907\n",
      "[Epoch 1/200] [Batch 84/216] [Loss: 0.2868 0.1230 -0.5795 0.4089 1.0878] Time_left: 6:13:31.180830\n",
      "[Epoch 1/200] [Batch 85/216] [Loss: 0.3322 0.0682 -0.7223 0.2898 1.5118] Time_left: 6:13:57.087367\n",
      "[Epoch 1/200] [Batch 86/216] [Loss: 0.4993 0.0866 -0.6691 0.3555 1.3930] Time_left: 6:13:52.381224\n",
      "[Epoch 1/200] [Batch 87/216] [Loss: 0.5397 0.0921 -0.6265 0.3682 1.1870] Time_left: 6:12:10.115710\n",
      "[Epoch 1/200] [Batch 88/216] [Loss: 0.6085 0.1189 -0.6385 0.3651 1.1897] Time_left: 6:14:17.128384\n",
      "[Epoch 1/200] [Batch 89/216] [Loss: 0.5223 0.1031 -0.5699 0.3855 0.8137] Time_left: 6:13:49.677260\n",
      "[Epoch 1/200] [Batch 90/216] [Loss: 0.5336 0.1114 -0.5670 0.5376 0.9906] Time_left: 6:13:09.167862\n",
      "[Epoch 1/200] [Batch 91/216] [Loss: 0.4000 0.1126 -0.5642 0.4243 0.8909] Time_left: 6:12:41.065058\n",
      "[Epoch 1/200] [Batch 92/216] [Loss: 0.3979 0.0809 -0.6369 0.3332 0.5440] Time_left: 6:11:01.032101\n",
      "[Epoch 1/200] [Batch 93/216] [Loss: 0.4664 0.0961 -0.6773 0.2870 0.4715] Time_left: 6:12:40.441681\n",
      "[Epoch 1/200] [Batch 94/216] [Loss: 0.3488 0.1339 -0.6511 0.3266 0.9236] Time_left: 6:13:56.859064\n",
      "[Epoch 1/200] [Batch 95/216] [Loss: 0.2928 0.1120 -0.5518 0.5291 0.7117] Time_left: 6:12:40.912396\n",
      "[Epoch 1/200] [Batch 96/216] [Loss: 0.2136 0.1008 -0.6267 0.3853 0.9194] Time_left: 6:13:43.266375\n",
      "[Epoch 1/200] [Batch 97/216] [Loss: 0.3163 0.1230 -0.5903 0.3450 0.4578] Time_left: 6:13:25.156442\n",
      "[Epoch 1/200] [Batch 98/216] [Loss: 0.2857 0.1065 -0.5743 0.4121 0.9233] Time_left: 6:11:02.509033\n",
      "[Epoch 1/200] [Batch 99/216] [Loss: 0.6337 0.1046 -0.5260 0.4624 0.8158] Time_left: 6:14:00.132794\n",
      "[Epoch 1/200] [Batch 100/216] [Loss: 0.1968 0.0860 -0.6343 0.2696 1.3907] Time_left: 6:09:39.584057\n",
      "[Epoch 1/200] [Batch 101/216] [Loss: 0.3684 0.1253 -0.5860 0.4207 0.8114] Time_left: 6:17:17.597470\n",
      "[Epoch 1/200] [Batch 102/216] [Loss: 1.1577 0.1133 -0.5320 0.5688 1.1843] Time_left: 6:10:44.974112\n",
      "[Epoch 1/200] [Batch 103/216] [Loss: 0.2933 0.0923 -0.6776 0.3211 1.2001] Time_left: 6:13:40.884496\n",
      "[Epoch 1/200] [Batch 104/216] [Loss: 0.3428 0.0931 -0.6722 0.3885 0.6075] Time_left: 6:11:26.240997\n",
      "[Epoch 1/200] [Batch 105/216] [Loss: 0.3082 0.1120 -0.5887 0.4581 0.3094] Time_left: 6:12:35.269353\n",
      "[Epoch 1/200] [Batch 106/216] [Loss: 0.2896 0.1047 -0.6631 0.3368 0.5489] Time_left: 6:13:48.557420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 107/216] [Loss: 0.3831 0.0931 -0.7122 0.2842 0.5411] Time_left: 6:13:48.075232\n",
      "[Epoch 1/200] [Batch 108/216] [Loss: 0.0983 0.0734 -0.6032 0.3500 1.3780] Time_left: 6:14:09.213492\n",
      "[Epoch 1/200] [Batch 109/216] [Loss: 0.5001 0.1232 -0.5301 0.6024 0.5162] Time_left: 6:12:41.331016\n",
      "[Epoch 1/200] [Batch 110/216] [Loss: 0.2159 0.1019 -0.5857 0.4254 0.2453] Time_left: 6:13:35.384503\n",
      "[Epoch 1/200] [Batch 111/216] [Loss: 0.2647 0.0864 -0.6631 0.3124 1.0936] Time_left: 6:15:21.801315\n",
      "[Epoch 1/200] [Batch 112/216] [Loss: 0.3973 0.0752 -0.7281 0.2717 1.1598] Time_left: 6:12:42.475067\n",
      "[Epoch 1/200] [Batch 113/216] [Loss: 0.1981 0.0951 -0.6356 0.3057 0.6154] Time_left: 6:13:06.535546\n",
      "[Epoch 1/200] [Batch 114/216] [Loss: 0.2630 0.1144 -0.6079 0.3141 0.4228] Time_left: 6:09:48.114274\n",
      "[Epoch 1/200] [Batch 115/216] [Loss: 0.3355 0.1126 -0.5754 0.4481 0.3403] Time_left: 6:16:05.540194\n",
      "[Epoch 1/200] [Batch 116/216] [Loss: 1.1481 0.1114 -0.5875 0.4443 1.1482] Time_left: 6:10:08.296954\n",
      "[Epoch 1/200] [Batch 117/216] [Loss: 0.0560 0.1126 -0.6043 0.3292 1.6944] Time_left: 6:13:23.967564\n",
      "[Epoch 1/200] [Batch 118/216] [Loss: 0.1285 0.1264 -0.4838 0.4594 0.3486] Time_left: 6:13:59.695445\n",
      "[Epoch 1/200] [Batch 119/216] [Loss: 0.1887 0.0944 -0.5960 0.4576 0.2248] Time_left: 6:13:36.565735\n",
      "[Epoch 1/200] [Batch 120/216] [Loss: 0.2108 0.0852 -0.6405 0.3207 0.8591] Time_left: 6:11:05.528893\n",
      "[Epoch 1/200] [Batch 121/216] [Loss: 1.1838 0.0891 -0.6937 0.2935 1.2316] Time_left: 6:14:20.372484\n",
      "[Epoch 1/200] [Batch 122/216] [Loss: 0.1569 0.0923 -0.5714 0.4194 0.8983] Time_left: 6:12:10.311205\n",
      "[Epoch 1/200] [Batch 123/216] [Loss: 0.2089 0.0951 -0.5666 0.4536 1.2175] Time_left: 6:10:35.316875\n",
      "[Epoch 1/200] [Batch 124/216] [Loss: 0.3372 0.1212 -0.5243 0.5502 0.8394] Time_left: 6:14:31.338720\n",
      "[Epoch 1/200] [Batch 125/216] [Loss: 1.4464 0.0802 -0.5696 0.3440 1.9829] Time_left: 6:10:51.752753\n",
      "[Epoch 1/200] [Batch 126/216] [Loss: 0.5333 0.0913 -0.6768 0.2370 1.3032] Time_left: 6:15:33.417818\n",
      "[Epoch 1/200] [Batch 127/216] [Loss: 0.5165 0.1013 -0.5318 0.4329 1.4008] Time_left: 6:13:29.275834\n",
      "[Epoch 1/200] [Batch 128/216] [Loss: 0.5988 0.1165 -0.5544 0.4678 1.3720] Time_left: 6:13:47.093660\n",
      "[Epoch 1/200] [Batch 129/216] [Loss: 0.6565 0.1376 -0.5857 0.4499 1.1139] Time_left: 6:12:39.544019\n",
      "[Epoch 1/200] [Batch 130/216] [Loss: 0.5426 0.1022 -0.6131 0.3652 1.0797] Time_left: 6:12:16.748796\n",
      "[Epoch 1/200] [Batch 131/216] [Loss: 0.5901 0.0838 -0.7099 0.2723 1.1817] Time_left: 6:15:00.107467\n",
      "[Epoch 1/200] [Batch 132/216] [Loss: 0.5141 0.1121 -0.6335 0.3497 1.0240] Time_left: 6:13:15.923644\n",
      "[Epoch 1/200] [Batch 133/216] [Loss: 0.5449 0.0751 -0.6517 0.3691 1.3351] Time_left: 6:13:16.535038\n",
      "[Epoch 1/200] [Batch 134/216] [Loss: 0.3706 0.0790 -0.6772 0.3117 0.8046] Time_left: 6:15:01.178312\n",
      "[Epoch 1/200] [Batch 135/216] [Loss: 0.3089 0.0828 -0.6536 0.2494 0.6636] Time_left: 6:13:42.694919\n",
      "[Epoch 1/200] [Batch 136/216] [Loss: 0.4162 0.1101 -0.6488 0.3011 0.5946] Time_left: 6:14:30.390007\n",
      "[Epoch 1/200] [Batch 137/216] [Loss: 0.2934 0.1281 -0.5185 0.4317 0.6903] Time_left: 6:11:10.458619\n",
      "[Epoch 1/200] [Batch 138/216] [Loss: 0.3082 0.0975 -0.6626 0.3449 0.4966] Time_left: 6:14:28.963200\n",
      "[Epoch 1/200] [Batch 139/216] [Loss: 0.2432 0.1058 -0.6039 0.3789 0.3089] Time_left: 6:12:55.165220\n",
      "[Epoch 1/200] [Batch 140/216] [Loss: 0.1842 0.0702 -0.6707 0.2462 0.9344] Time_left: 6:14:46.423603\n",
      "[Epoch 1/200] [Batch 141/216] [Loss: 0.4313 0.0768 -0.6870 0.2589 1.0727] Time_left: 6:14:48.401328\n",
      "[Epoch 1/200] [Batch 142/216] [Loss: 1.3035 0.1095 -0.5535 0.3998 1.3064] Time_left: 6:11:06.327634\n",
      "[Epoch 1/200] [Batch 143/216] [Loss: 0.0928 0.0860 -0.6685 0.2664 0.7838] Time_left: 6:15:18.341073\n",
      "[Epoch 1/200] [Batch 144/216] [Loss: 0.2133 0.0921 -0.5911 0.4086 1.1767] Time_left: 6:10:27.394781\n",
      "[Epoch 1/200] [Batch 145/216] [Loss: 0.1878 0.0906 -0.6114 0.3595 0.6992] Time_left: 6:15:52.118243\n",
      "[Epoch 1/200] [Batch 146/216] [Loss: 0.7707 0.1527 -0.4888 0.3691 1.3177] Time_left: 6:10:51.910952\n",
      "[Epoch 1/200] [Batch 147/216] [Loss: 0.5162 0.0847 -0.6661 0.2754 1.0415] Time_left: 6:16:04.628411\n",
      "[Epoch 1/200] [Batch 148/216] [Loss: 0.4605 0.0980 -0.6446 0.3221 0.5608] Time_left: 6:10:57.306191\n",
      "[Epoch 1/200] [Batch 149/216] [Loss: 0.3513 0.0978 -0.6309 0.3895 0.7409] Time_left: 6:16:34.549897\n",
      "[Epoch 1/200] [Batch 150/216] [Loss: 0.4065 0.0935 -0.6469 0.3806 0.8641] Time_left: 6:14:01.887976\n",
      "[Epoch 1/200] [Batch 151/216] [Loss: 0.2831 0.0844 -0.6716 0.3290 0.8528] Time_left: 6:12:38.144970\n",
      "[Epoch 1/200] [Batch 152/216] [Loss: 0.4418 0.1024 -0.6149 0.4143 0.6014] Time_left: 6:14:25.542816\n",
      "[Epoch 1/200] [Batch 153/216] [Loss: 0.3652 0.1006 -0.5802 0.3805 0.8832] Time_left: 6:13:35.930641\n",
      "[Epoch 1/200] [Batch 154/216] [Loss: 0.1395 0.1046 -0.5904 0.3445 0.2164] Time_left: 6:12:46.320758\n",
      "[Epoch 1/200] [Batch 155/216] [Loss: 0.1640 0.1048 -0.6177 0.4270 0.5757] Time_left: 6:13:55.704622\n",
      "[Epoch 1/200] [Batch 156/216] [Loss: 0.3480 0.1161 -0.5027 0.5054 0.4137] Time_left: 6:14:22.709610\n",
      "[Epoch 1/200] [Batch 157/216] [Loss: 0.6486 0.0852 -0.7126 0.2025 1.3975] Time_left: 6:11:44.857849\n",
      "[Epoch 1/200] [Batch 158/216] [Loss: 0.3075 0.1002 -0.6197 0.3300 0.3539] Time_left: 6:14:32.493992\n",
      "[Epoch 1/200] [Batch 159/216] [Loss: 0.1196 0.0959 -0.6005 0.4294 0.2860] Time_left: 6:13:36.527456\n",
      "[Epoch 1/200] [Batch 160/216] [Loss: 0.1947 0.1201 -0.5973 0.4186 0.2061] Time_left: 6:13:09.192453\n",
      "[Epoch 1/200] [Batch 161/216] [Loss: 0.0580 0.0923 -0.6475 0.3440 1.1187] Time_left: 6:15:28.268214\n",
      "[Epoch 1/200] [Batch 162/216] [Loss: 0.3480 0.1047 -0.5567 0.4066 0.4879] Time_left: 6:15:01.993624\n",
      "[Epoch 1/200] [Batch 163/216] [Loss: 0.7928 0.0741 -0.6223 0.3150 0.8416] Time_left: 6:13:38.925778\n",
      "[Epoch 1/200] [Batch 164/216] [Loss: 0.1881 0.0860 -0.6738 0.3582 0.8615] Time_left: 6:13:53.307490\n",
      "[Epoch 1/200] [Batch 165/216] [Loss: 0.0447 0.0964 -0.6605 0.3469 0.2606] Time_left: 6:15:08.390300\n",
      "[Epoch 1/200] [Batch 166/216] [Loss: 0.0540 0.1205 -0.5661 0.4064 0.0821] Time_left: 6:14:32.440771\n",
      "[Epoch 1/200] [Batch 167/216] [Loss: 0.9290 0.0959 -0.6024 0.3352 1.2294] Time_left: 6:12:11.458995\n",
      "[Epoch 1/200] [Batch 168/216] [Loss: 0.1303 0.1201 -0.6528 0.3179 1.4792] Time_left: 6:13:58.030930\n",
      "[Epoch 1/200] [Batch 169/216] [Loss: 0.2191 0.0740 -0.6952 0.1867 0.8243] Time_left: 6:13:59.905727\n",
      "[Epoch 1/200] [Batch 170/216] [Loss: 0.2684 0.1076 -0.5856 0.4711 0.5263] Time_left: 6:12:17.427575\n",
      "[Epoch 1/200] [Batch 171/216] [Loss: 0.5462 0.0660 -0.6732 0.2372 0.9142] Time_left: 6:14:33.766859\n",
      "[Epoch 1/200] [Batch 172/216] [Loss: 0.2719 0.1122 -0.6125 0.3325 0.3258] Time_left: 6:14:17.247285\n",
      "[Epoch 1/200] [Batch 173/216] [Loss: 0.3998 0.0991 -0.6460 0.3681 0.5377] Time_left: 6:13:16.930488\n",
      "[Epoch 1/200] [Batch 174/216] [Loss: 0.1744 0.0831 -0.6544 0.2726 0.1933] Time_left: 6:14:24.792216\n",
      "[Epoch 1/200] [Batch 175/216] [Loss: 0.1376 0.1159 -0.6290 0.2805 0.4652] Time_left: 6:14:34.708670\n",
      "[Epoch 1/200] [Batch 176/216] [Loss: 0.0397 0.0930 -0.6599 0.2701 0.5548] Time_left: 6:14:48.788774\n",
      "[Epoch 1/200] [Batch 177/216] [Loss: 0.5378 0.0901 -0.7246 0.2091 0.5378] Time_left: 6:13:35.362089\n",
      "[Epoch 1/200] [Batch 178/216] [Loss: 0.0598 0.0994 -0.6202 0.3446 0.8339] Time_left: 6:12:55.923943\n",
      "[Epoch 1/200] [Batch 179/216] [Loss: 0.3176 0.1111 -0.6939 0.3214 1.1151] Time_left: 6:13:31.324600\n",
      "[Epoch 1/200] [Batch 180/216] [Loss: 0.2511 0.0768 -0.7082 0.3007 0.4182] Time_left: 6:12:58.674846\n",
      "[Epoch 1/200] [Batch 181/216] [Loss: 0.4842 0.0698 -0.6867 0.2283 0.8046] Time_left: 6:13:44.686967\n",
      "[Epoch 1/200] [Batch 182/216] [Loss: 0.2025 0.0839 -0.6865 0.3612 0.2302] Time_left: 6:12:35.852185\n",
      "[Epoch 1/200] [Batch 183/216] [Loss: 0.1804 0.0920 -0.5948 0.3950 0.5296] Time_left: 6:14:21.620507\n",
      "[Epoch 1/200] [Batch 184/216] [Loss: 0.2026 0.1079 -0.6076 0.3388 0.2125] Time_left: 6:13:18.543262\n",
      "[Epoch 1/200] [Batch 185/216] [Loss: 0.1420 0.0992 -0.5170 0.3668 0.3508] Time_left: 6:12:51.917904\n",
      "[Epoch 1/200] [Batch 186/216] [Loss: 0.1008 0.0872 -0.6232 0.3668 1.0889] Time_left: 6:13:56.230372\n",
      "[Epoch 1/200] [Batch 187/216] [Loss: 0.1399 0.0956 -0.6000 0.3967 0.1399] Time_left: 6:13:02.831082\n",
      "[Epoch 1/200] [Batch 188/216] [Loss: 0.0559 0.1052 -0.5753 0.3703 0.0570] Time_left: 6:12:21.290568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 189/216] [Loss: 0.0703 0.0822 -0.6769 0.2640 0.7049] Time_left: 6:13:55.831025\n",
      "[Epoch 1/200] [Batch 190/216] [Loss: 1.3589 0.0796 -0.7050 0.2380 1.5431] Time_left: 6:13:32.544126\n",
      "[Epoch 1/200] [Batch 191/216] [Loss: 0.0494 0.0987 -0.5864 0.4789 1.1336] Time_left: 6:14:12.698346\n",
      "[Epoch 1/200] [Batch 192/216] [Loss: 0.2352 0.0669 -0.7159 0.2349 1.2211] Time_left: 6:15:17.744539\n",
      "[Epoch 1/200] [Batch 193/216] [Loss: 0.3579 0.0939 -0.6669 0.3099 0.5585] Time_left: 6:12:25.403590\n",
      "[Epoch 1/200] [Batch 194/216] [Loss: 0.6769 0.1084 -0.6099 0.4268 0.8805] Time_left: 6:15:42.849863\n",
      "[Epoch 1/200] [Batch 195/216] [Loss: 0.6746 0.0904 -0.6772 0.2982 0.8162] Time_left: 6:13:16.224598\n",
      "[Epoch 1/200] [Batch 196/216] [Loss: 0.3618 0.0999 -0.6471 0.3057 0.5689] Time_left: 6:13:27.045204\n",
      "[Epoch 1/200] [Batch 197/216] [Loss: 0.2058 0.0718 -0.7048 0.2636 1.0370] Time_left: 6:13:54.003603\n",
      "[Epoch 1/200] [Batch 198/216] [Loss: 1.1451 0.1012 -0.6042 0.4522 1.1451] Time_left: 6:12:23.261842\n",
      "[Epoch 1/200] [Batch 199/216] [Loss: 0.2063 0.1087 -0.6507 0.3078 0.8806] Time_left: 6:13:47.936203\n",
      "[Epoch 1/200] [Batch 200/216] [Loss: 0.1420 0.1168 -0.5926 0.4631 1.0935] Time_left: 6:15:24.561569\n",
      "[Epoch 1/200] [Batch 201/216] [Loss: 0.2178 0.1028 -0.5877 0.4134 0.4132] Time_left: 6:13:33.117448\n",
      "[Epoch 1/200] [Batch 202/216] [Loss: 0.2866 0.0671 -0.7391 0.1794 1.3114] Time_left: 6:14:48.634745\n",
      "[Epoch 1/200] [Batch 203/216] [Loss: 0.5150 0.0917 -0.6535 0.3780 0.6174] Time_left: 6:13:44.931619\n",
      "[Epoch 1/200] [Batch 204/216] [Loss: 0.6129 0.0919 -0.6631 0.3522 1.1120] Time_left: 6:14:05.306311\n",
      "[Epoch 1/200] [Batch 205/216] [Loss: 0.5947 0.1005 -0.6189 0.3083 0.7607] Time_left: 6:12:10.702378\n",
      "[Epoch 1/200] [Batch 206/216] [Loss: 0.3160 0.0615 -0.6744 0.2090 1.1607] Time_left: 6:14:15.353562\n",
      "[Epoch 1/200] [Batch 207/216] [Loss: 0.2614 0.0942 -0.6471 0.3497 0.8086] Time_left: 6:12:57.552088\n",
      "[Epoch 1/200] [Batch 208/216] [Loss: 0.5516 0.1062 -0.6535 0.3108 0.6268] Time_left: 6:12:19.926485\n",
      "[Epoch 1/200] [Batch 209/216] [Loss: 0.2641 0.0906 -0.5944 0.3364 0.9187] Time_left: 6:16:46.947869\n",
      "[Epoch 1/200] [Batch 210/216] [Loss: 0.2171 0.1197 -0.5903 0.4109 0.5242] Time_left: 6:14:31.712442\n",
      "[Epoch 1/200] [Batch 211/216] [Loss: 0.2180 0.1235 -0.5636 0.5214 0.2180] Time_left: 6:13:52.322971\n",
      "[Epoch 1/200] [Batch 212/216] [Loss: 0.2121 0.0964 -0.5903 0.3699 0.6515] Time_left: 6:13:21.807262\n",
      "[Epoch 1/200] [Batch 213/216] [Loss: 0.2069 0.0852 -0.7138 0.2526 0.5343] Time_left: 6:12:49.865320\n",
      "[Epoch 1/200] [Batch 214/216] [Loss: 0.2304 0.1314 -0.5446 0.5670 0.4193] Time_left: 6:12:51.840611\n",
      "[Epoch 1/200] [Batch 215/216] [Loss: 0.1427 0.0600 -0.7527 0.1748 0.2928] Time_left: 3:42:45.485848\n",
      "[Epoch 2/200] [Batch 0/216] [Loss: 1.5697 0.0850 -0.6807 0.2632 1.6325] Time_left: 8:22:02.080479\n",
      "[Epoch 2/200] [Batch 1/216] [Loss: 0.0323 0.0891 -0.6059 0.2763 1.6897] Time_left: 6:26:11.732547\n",
      "[Epoch 2/200] [Batch 2/216] [Loss: 0.1753 0.0930 -0.6030 0.3782 0.8838] Time_left: 6:13:16.044341\n",
      "[Epoch 2/200] [Batch 3/216] [Loss: 0.1401 0.1144 -0.5552 0.4181 0.6646] Time_left: 6:13:31.253035\n",
      "[Epoch 2/200] [Batch 4/216] [Loss: 0.1678 0.0906 -0.6503 0.3364 0.5725] Time_left: 6:12:38.322916\n",
      "[Epoch 2/200] [Batch 5/216] [Loss: 0.2000 0.1148 -0.5533 0.6096 0.2007] Time_left: 6:15:42.623995\n",
      "[Epoch 2/200] [Batch 6/216] [Loss: 0.5290 0.0763 -0.6319 0.2573 1.3068] Time_left: 6:12:49.501366\n",
      "[Epoch 2/200] [Batch 7/216] [Loss: 0.2712 0.1152 -0.6466 0.3723 0.6123] Time_left: 6:14:25.494474\n",
      "[Epoch 2/200] [Batch 8/216] [Loss: 0.1848 0.0936 -0.6576 0.4278 0.6194] Time_left: 6:15:09.448919\n",
      "[Epoch 2/200] [Batch 9/216] [Loss: 0.2627 0.0763 -0.7418 0.2509 0.7939] Time_left: 6:13:07.790981\n",
      "[Epoch 2/200] [Batch 10/216] [Loss: 0.2711 0.1033 -0.6262 0.3126 0.6398] Time_left: 6:12:08.171034\n",
      "[Epoch 2/200] [Batch 11/216] [Loss: 0.2042 0.0903 -0.6287 0.3560 0.3841] Time_left: 6:13:12.901034\n",
      "[Epoch 2/200] [Batch 12/216] [Loss: 0.2697 0.0997 -0.6317 0.3978 0.2975] Time_left: 6:14:05.986633\n",
      "[Epoch 2/200] [Batch 13/216] [Loss: 0.4721 0.0737 -0.7856 0.1791 1.0141] Time_left: 6:15:13.575199\n",
      "[Epoch 2/200] [Batch 14/216] [Loss: 0.3266 0.0959 -0.6795 0.3458 0.3281] Time_left: 6:14:40.368753\n",
      "[Epoch 2/200] [Batch 15/216] [Loss: 0.1001 0.0972 -0.6046 0.4132 0.3732] Time_left: 6:14:04.850001\n",
      "[Epoch 2/200] [Batch 16/216] [Loss: 0.0929 0.0965 -0.6753 0.3044 0.4563] Time_left: 6:12:51.221741\n",
      "[Epoch 2/200] [Batch 17/216] [Loss: 0.7037 0.1104 -0.5727 0.3729 0.7037] Time_left: 6:12:55.050716\n",
      "[Epoch 2/200] [Batch 18/216] [Loss: 0.0347 0.1280 -0.5474 0.4158 0.7001] Time_left: 6:14:58.589158\n",
      "[Epoch 2/200] [Batch 19/216] [Loss: 0.0393 0.1075 -0.5843 0.3828 2.0153] Time_left: 6:12:16.160480\n",
      "[Epoch 2/200] [Batch 20/216] [Loss: 0.1081 0.0921 -0.6316 0.3087 0.8984] Time_left: 6:15:04.242874\n",
      "[Epoch 2/200] [Batch 21/216] [Loss: 0.2784 0.1222 -0.6465 0.3518 0.3314] Time_left: 6:14:39.551964\n",
      "[Epoch 2/200] [Batch 22/216] [Loss: 0.2435 0.0683 -0.6996 0.2519 1.1535] Time_left: 6:13:33.342255\n",
      "[Epoch 2/200] [Batch 23/216] [Loss: 0.2299 0.0715 -0.6982 0.2853 0.4936] Time_left: 6:12:34.921697\n",
      "[Epoch 2/200] [Batch 24/216] [Loss: 0.4847 0.1064 -0.6338 0.2796 0.4848] Time_left: 6:13:17.139616\n",
      "[Epoch 2/200] [Batch 25/216] [Loss: 0.3056 0.0929 -0.7459 0.2368 1.1655] Time_left: 6:13:59.192483\n",
      "[Epoch 2/200] [Batch 26/216] [Loss: 0.2810 0.0876 -0.6852 0.2870 0.7336] Time_left: 6:16:00.535537\n",
      "[Epoch 2/200] [Batch 27/216] [Loss: 0.9470 0.1284 -0.5848 0.3601 1.2702] Time_left: 6:13:01.892353\n",
      "[Epoch 2/200] [Batch 28/216] [Loss: 0.2975 0.0939 -0.6719 0.2489 0.6080] Time_left: 6:13:32.468600\n",
      "[Epoch 2/200] [Batch 29/216] [Loss: 0.2427 0.0715 -0.7027 0.2210 1.0151] Time_left: 6:11:22.554489\n",
      "[Epoch 2/200] [Batch 30/216] [Loss: 0.2430 0.1309 -0.5574 0.4026 0.2971] Time_left: 6:14:17.262528\n",
      "[Epoch 2/200] [Batch 31/216] [Loss: 0.2565 0.1249 -0.5785 0.3472 0.6161] Time_left: 6:16:21.168733\n",
      "[Epoch 2/200] [Batch 32/216] [Loss: 0.2504 0.0919 -0.6282 0.3511 0.5505] Time_left: 6:15:28.574280\n",
      "[Epoch 2/200] [Batch 33/216] [Loss: 0.2435 0.0681 -0.7203 0.1793 0.5532] Time_left: 6:12:06.481737\n",
      "[Epoch 2/200] [Batch 34/216] [Loss: 0.1930 0.1029 -0.5983 0.4089 0.2112] Time_left: 6:14:08.303760\n",
      "[Epoch 2/200] [Batch 35/216] [Loss: 0.2013 0.0756 -0.6793 0.3166 0.5637] Time_left: 6:13:57.365972\n",
      "[Epoch 2/200] [Batch 36/216] [Loss: 0.1915 0.1132 -0.5836 0.4180 0.2816] Time_left: 6:14:42.483613\n",
      "[Epoch 2/200] [Batch 37/216] [Loss: 0.7625 0.0955 -0.6670 0.3599 1.2310] Time_left: 6:14:02.143312\n",
      "[Epoch 2/200] [Batch 38/216] [Loss: 0.1378 0.1484 -0.5447 0.3204 1.4109] Time_left: 6:14:19.456649\n",
      "[Epoch 2/200] [Batch 39/216] [Loss: 0.1692 0.1092 -0.5590 0.3201 0.1962] Time_left: 6:12:47.774292\n",
      "[Epoch 2/200] [Batch 40/216] [Loss: 0.2186 0.1103 -0.5545 0.3932 1.4054] Time_left: 6:12:09.588923\n",
      "[Epoch 2/200] [Batch 41/216] [Loss: 0.3264 0.1176 -0.5669 0.4151 0.9194] Time_left: 6:16:22.007315\n",
      "[Epoch 2/200] [Batch 42/216] [Loss: 0.4526 0.0968 -0.7357 0.3430 1.2744] Time_left: 6:15:01.238379\n",
      "[Epoch 2/200] [Batch 43/216] [Loss: 0.3331 0.0877 -0.7105 0.2287 0.8713] Time_left: 6:12:33.049195\n",
      "[Epoch 2/200] [Batch 44/216] [Loss: 0.4978 0.0717 -0.7099 0.2145 1.0389] Time_left: 6:12:49.017461\n",
      "[Epoch 2/200] [Batch 45/216] [Loss: 0.4471 0.0643 -0.6980 0.2344 1.0968] Time_left: 6:13:54.702611\n",
      "[Epoch 2/200] [Batch 46/216] [Loss: 0.3752 0.1163 -0.5565 0.4120 0.6330] Time_left: 6:16:23.316782\n",
      "[Epoch 2/200] [Batch 47/216] [Loss: 0.3846 0.0750 -0.6993 0.2518 1.0255] Time_left: 6:13:23.829285\n",
      "[Epoch 2/200] [Batch 48/216] [Loss: 0.3617 0.0760 -0.6908 0.2772 0.5747] Time_left: 6:13:22.011337\n",
      "[Epoch 2/200] [Batch 49/216] [Loss: 0.4030 0.0761 -0.7116 0.2527 0.9912] Time_left: 6:12:03.520746\n",
      "[Epoch 2/200] [Batch 50/216] [Loss: 0.2927 0.0880 -0.6734 0.2936 0.6975] Time_left: 6:13:32.053763\n",
      "[Epoch 2/200] [Batch 51/216] [Loss: 0.3442 0.1049 -0.6322 0.3542 0.7129] Time_left: 6:13:28.198771\n",
      "[Epoch 2/200] [Batch 52/216] [Loss: 0.3308 0.0857 -0.6707 0.3183 0.7909] Time_left: 6:11:38.009785\n",
      "[Epoch 2/200] [Batch 53/216] [Loss: 1.6830 0.0811 -0.6822 0.2706 2.0081] Time_left: 6:15:10.619569\n",
      "[Epoch 2/200] [Batch 54/216] [Loss: 0.2698 0.0734 -0.6912 0.2350 0.9364] Time_left: 6:14:05.975298\n",
      "[Epoch 2/200] [Batch 55/216] [Loss: 0.2320 0.0846 -0.6497 0.3486 0.6372] Time_left: 6:13:57.302945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 56/216] [Loss: 0.2187 0.0775 -0.6513 0.2614 0.6745] Time_left: 6:12:17.805815\n",
      "[Epoch 2/200] [Batch 57/216] [Loss: 2.3648 0.1275 -0.5175 0.3496 2.6966] Time_left: 6:12:20.154461\n",
      "[Epoch 2/200] [Batch 58/216] [Loss: 0.2516 0.0776 -0.6836 0.3326 0.9511] Time_left: 6:13:45.472896\n",
      "[Epoch 2/200] [Batch 59/216] [Loss: 0.2054 0.1175 -0.5772 0.4215 0.7213] Time_left: 6:15:53.360842\n",
      "[Epoch 2/200] [Batch 60/216] [Loss: 0.2520 0.0939 -0.5985 0.3754 1.1846] Time_left: 6:13:44.300580\n",
      "[Epoch 2/200] [Batch 61/216] [Loss: 0.2284 0.0896 -0.6426 0.3787 0.7506] Time_left: 6:13:40.140494\n",
      "[Epoch 2/200] [Batch 62/216] [Loss: 0.3521 0.0790 -0.6622 0.2762 0.8891] Time_left: 6:12:27.741459\n",
      "[Epoch 2/200] [Batch 63/216] [Loss: 0.4815 0.0742 -0.7110 0.2450 0.7888] Time_left: 6:13:58.069167\n",
      "[Epoch 2/200] [Batch 64/216] [Loss: 0.7214 0.0778 -0.6600 0.2410 0.9552] Time_left: 6:14:32.058784\n",
      "[Epoch 2/200] [Batch 65/216] [Loss: 0.3477 0.0842 -0.6736 0.3016 0.5529] Time_left: 6:14:13.572939\n",
      "[Epoch 2/200] [Batch 66/216] [Loss: 0.3104 0.0888 -0.6242 0.2768 0.8638] Time_left: 6:13:36.202273\n",
      "[Epoch 2/200] [Batch 67/216] [Loss: 0.2868 0.1314 -0.6138 0.3689 0.4529] Time_left: 6:12:15.208982\n",
      "[Epoch 2/200] [Batch 68/216] [Loss: 0.1814 0.0851 -0.6597 0.2610 1.2291] Time_left: 6:13:00.314803\n",
      "[Epoch 2/200] [Batch 69/216] [Loss: 0.3670 0.0661 -0.8064 0.1260 1.3130] Time_left: 6:12:16.015664\n",
      "[Epoch 2/200] [Batch 70/216] [Loss: 0.2607 0.0884 -0.7005 0.1768 0.2655] Time_left: 6:13:32.524593\n",
      "[Epoch 2/200] [Batch 71/216] [Loss: 0.3550 0.0855 -0.6158 0.3554 0.5223] Time_left: 6:14:25.769167\n",
      "[Epoch 2/200] [Batch 72/216] [Loss: 2.6015 0.0743 -0.6838 0.2346 2.6065] Time_left: 6:14:47.230762\n",
      "[Epoch 2/200] [Batch 73/216] [Loss: 0.1663 0.0970 -0.6274 0.3601 0.5883] Time_left: 6:12:56.411568\n",
      "[Epoch 2/200] [Batch 74/216] [Loss: 0.1385 0.1141 -0.6510 0.3375 0.5709] Time_left: 6:11:47.443585\n",
      "[Epoch 2/200] [Batch 75/216] [Loss: 0.1757 0.0795 -0.7003 0.2924 0.5004] Time_left: 6:13:37.320401\n",
      "[Epoch 2/200] [Batch 76/216] [Loss: 0.1607 0.1163 -0.5883 0.4207 0.1608] Time_left: 6:11:37.064848\n",
      "[Epoch 2/200] [Batch 77/216] [Loss: 0.2579 0.0918 -0.5967 0.3361 0.7277] Time_left: 6:13:10.152649\n",
      "[Epoch 2/200] [Batch 78/216] [Loss: 1.0398 0.1107 -0.6356 0.2721 1.0667] Time_left: 6:15:15.714347\n",
      "[Epoch 2/200] [Batch 79/216] [Loss: 0.1868 0.0861 -0.6898 0.3130 0.8911] Time_left: 6:14:58.546138\n",
      "[Epoch 2/200] [Batch 80/216] [Loss: 0.2447 0.0817 -0.7272 0.2409 1.7514] Time_left: 6:12:27.695770\n",
      "[Epoch 2/200] [Batch 81/216] [Loss: 0.4487 0.1092 -0.6651 0.3751 1.0488] Time_left: 6:12:23.722128\n",
      "[Epoch 2/200] [Batch 82/216] [Loss: 0.4491 0.0982 -0.6301 0.3752 1.0833] Time_left: 6:12:44.346784\n",
      "[Epoch 2/200] [Batch 83/216] [Loss: 0.5616 0.0982 -0.5808 0.3777 1.3429] Time_left: 6:14:40.806289\n",
      "[Epoch 2/200] [Batch 84/216] [Loss: 0.3071 0.0782 -0.6619 0.2966 1.5824] Time_left: 6:12:50.941601\n",
      "[Epoch 2/200] [Batch 85/216] [Loss: 0.4119 0.0685 -0.6675 0.3041 1.4829] Time_left: 6:15:06.293057\n",
      "[Epoch 2/200] [Batch 86/216] [Loss: 0.5667 0.1047 -0.6673 0.3604 1.1699] Time_left: 6:12:56.436674\n",
      "[Epoch 2/200] [Batch 87/216] [Loss: 0.5720 0.0720 -0.7157 0.2804 1.0115] Time_left: 6:13:00.532293\n",
      "[Epoch 2/200] [Batch 88/216] [Loss: 0.4794 0.0771 -0.6137 0.3805 1.2728] Time_left: 6:11:28.945541\n",
      "[Epoch 2/200] [Batch 89/216] [Loss: 0.5982 0.0598 -0.6867 0.2378 1.0545] Time_left: 6:14:07.343744\n",
      "[Epoch 2/200] [Batch 90/216] [Loss: 0.5527 0.0927 -0.6354 0.3267 1.1196] Time_left: 6:14:34.189150\n",
      "[Epoch 2/200] [Batch 91/216] [Loss: 0.4015 0.0914 -0.6648 0.2614 0.6526] Time_left: 6:14:03.646331\n",
      "[Epoch 2/200] [Batch 92/216] [Loss: 0.3887 0.1127 -0.6674 0.2769 0.7829] Time_left: 6:13:50.636016\n",
      "[Epoch 2/200] [Batch 93/216] [Loss: 0.3176 0.1299 -0.6148 0.4021 0.3209] Time_left: 6:11:19.904079\n",
      "[Epoch 2/200] [Batch 94/216] [Loss: 0.3461 0.1024 -0.6363 0.3696 0.6788] Time_left: 6:13:25.705788\n",
      "[Epoch 2/200] [Batch 95/216] [Loss: 0.2823 0.1037 -0.6964 0.2650 0.7503] Time_left: 6:13:09.807776\n",
      "[Epoch 2/200] [Batch 96/216] [Loss: 0.3120 0.0867 -0.6275 0.3802 0.5191] Time_left: 6:13:42.368282\n",
      "[Epoch 2/200] [Batch 97/216] [Loss: 0.2668 0.1039 -0.6225 0.3759 1.0078] Time_left: 6:13:32.137248\n",
      "[Epoch 2/200] [Batch 98/216] [Loss: 0.2743 0.1107 -0.5984 0.4541 0.3458] Time_left: 6:11:57.081521\n",
      "[Epoch 2/200] [Batch 99/216] [Loss: 0.1284 0.1088 -0.5901 0.3527 0.1707] Time_left: 6:12:20.322825\n",
      "[Epoch 2/200] [Batch 100/216] [Loss: 0.1491 0.0804 -0.6876 0.2229 1.2980] Time_left: 6:12:58.374677\n",
      "[Epoch 2/200] [Batch 101/216] [Loss: 0.3195 0.0736 -0.7057 0.2310 0.5300] Time_left: 6:12:35.490813\n",
      "[Epoch 2/200] [Batch 102/216] [Loss: 0.3393 0.1054 -0.6728 0.2384 0.5196] Time_left: 6:14:38.489914\n",
      "[Epoch 2/200] [Batch 103/216] [Loss: 0.2450 0.1112 -0.6494 0.2877 0.2764] Time_left: 6:10:26.396152\n",
      "[Epoch 2/200] [Batch 104/216] [Loss: 0.1356 0.1025 -0.6027 0.2997 0.6404] Time_left: 6:14:27.182953\n",
      "[Epoch 2/200] [Batch 105/216] [Loss: 0.2786 0.0528 -0.7525 0.1656 0.6474] Time_left: 6:14:08.967843\n",
      "[Epoch 2/200] [Batch 106/216] [Loss: 1.4563 0.0767 -0.6524 0.2154 1.4728] Time_left: 6:13:00.252494\n",
      "[Epoch 2/200] [Batch 107/216] [Loss: 0.0904 0.0817 -0.6210 0.3479 0.4761] Time_left: 6:12:29.021122\n",
      "[Epoch 2/200] [Batch 108/216] [Loss: 0.1760 0.0964 -0.6880 0.3190 0.3413] Time_left: 6:05:42.534485\n",
      "[Epoch 2/200] [Batch 109/216] [Loss: 0.2945 0.0992 -0.7331 0.3349 1.0767] Time_left: 6:12:27.780130\n",
      "[Epoch 2/200] [Batch 110/216] [Loss: 0.3378 0.0676 -0.6926 0.2187 1.5262] Time_left: 6:10:48.267175\n",
      "[Epoch 2/200] [Batch 111/216] [Loss: 0.2525 0.1200 -0.5113 0.5322 0.5186] Time_left: 6:11:36.369453\n",
      "[Epoch 2/200] [Batch 112/216] [Loss: 0.2448 0.0748 -0.6735 0.2431 1.3814] Time_left: 6:11:05.977524\n",
      "[Epoch 2/200] [Batch 113/216] [Loss: 0.4247 0.0957 -0.6321 0.3325 0.6464] Time_left: 6:10:26.668129\n",
      "[Epoch 2/200] [Batch 114/216] [Loss: 0.4861 0.1229 -0.5508 0.4389 0.5055] Time_left: 6:11:33.072568\n",
      "[Epoch 2/200] [Batch 115/216] [Loss: 0.3418 0.1079 -0.6466 0.3450 0.4135] Time_left: 6:11:03.160736\n",
      "[Epoch 2/200] [Batch 116/216] [Loss: 0.4347 0.0825 -0.6938 0.2684 0.7706] Time_left: 6:11:50.392537\n",
      "[Epoch 2/200] [Batch 117/216] [Loss: 0.1701 0.1007 -0.6484 0.2692 0.1935] Time_left: 6:11:21.884945\n",
      "[Epoch 2/200] [Batch 118/216] [Loss: 1.6809 0.0781 -0.7730 0.2164 1.6816] Time_left: 6:10:54.609060\n",
      "[Epoch 2/200] [Batch 119/216] [Loss: 0.0725 0.1148 -0.5771 0.5472 1.8509] Time_left: 6:11:02.252420\n",
      "[Epoch 2/200] [Batch 120/216] [Loss: 0.1947 0.1251 -0.5895 0.4714 1.6325] Time_left: 6:10:24.728806\n",
      "[Epoch 2/200] [Batch 121/216] [Loss: 0.3436 0.0783 -0.6487 0.2590 1.6560] Time_left: 6:11:43.994704\n",
      "[Epoch 2/200] [Batch 122/216] [Loss: 0.4758 0.1027 -0.6506 0.3233 1.4227] Time_left: 6:10:49.136065\n",
      "[Epoch 2/200] [Batch 123/216] [Loss: 0.6043 0.0764 -0.7785 0.1542 1.3673] Time_left: 6:11:36.431444\n",
      "[Epoch 2/200] [Batch 124/216] [Loss: 0.5245 0.0801 -0.7234 0.2790 1.3399] Time_left: 6:10:07.952834\n",
      "[Epoch 2/200] [Batch 125/216] [Loss: 0.6809 0.0995 -0.5676 0.4304 1.2983] Time_left: 6:11:46.457504\n",
      "[Epoch 2/200] [Batch 126/216] [Loss: 0.6374 0.1268 -0.5660 0.4192 1.2230] Time_left: 6:11:17.315300\n",
      "[Epoch 2/200] [Batch 127/216] [Loss: 0.7264 0.1156 -0.6282 0.4128 1.1531] Time_left: 6:10:50.817704\n",
      "[Epoch 2/200] [Batch 128/216] [Loss: 0.6697 0.0805 -0.6715 0.2586 1.4077] Time_left: 6:11:53.732777\n",
      "[Epoch 2/200] [Batch 129/216] [Loss: 0.6259 0.0892 -0.6315 0.3285 1.2410] Time_left: 6:10:54.277576\n",
      "[Epoch 2/200] [Batch 130/216] [Loss: 0.6834 0.0779 -0.6448 0.3472 1.1740] Time_left: 6:10:55.707466\n",
      "[Epoch 2/200] [Batch 131/216] [Loss: 0.7403 0.0515 -0.7649 0.1717 1.3240] Time_left: 6:11:39.639023\n",
      "[Epoch 2/200] [Batch 132/216] [Loss: 0.6358 0.0825 -0.6413 0.2468 1.2354] Time_left: 6:14:30.277894\n",
      "[Epoch 2/200] [Batch 133/216] [Loss: 0.5698 0.0925 -0.6463 0.3015 1.1065] Time_left: 6:07:49.596418\n",
      "[Epoch 2/200] [Batch 134/216] [Loss: 0.5918 0.0998 -0.6031 0.4094 0.7890] Time_left: 6:11:36.870550\n",
      "[Epoch 2/200] [Batch 135/216] [Loss: 0.6232 0.1163 -0.6042 0.4505 0.7728] Time_left: 6:11:06.341964\n",
      "[Epoch 2/200] [Batch 136/216] [Loss: 0.6202 0.1011 -0.6264 0.3315 0.9988] Time_left: 6:11:08.868963\n",
      "[Epoch 2/200] [Batch 137/216] [Loss: 0.5065 0.0925 -0.6775 0.3243 0.9371] Time_left: 6:12:03.212005\n",
      "[Epoch 2/200] [Batch 138/216] [Loss: 0.6169 0.1094 -0.6552 0.3003 1.0277] Time_left: 6:10:33.358870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 139/216] [Loss: 0.4426 0.1126 -0.6409 0.2920 0.4811] Time_left: 6:11:48.474433\n",
      "[Epoch 2/200] [Batch 140/216] [Loss: 0.3858 0.0820 -0.6689 0.3480 0.5882] Time_left: 6:11:09.726918\n",
      "[Epoch 2/200] [Batch 141/216] [Loss: 0.5999 0.0915 -0.6331 0.3435 0.7847] Time_left: 6:10:53.675329\n",
      "[Epoch 2/200] [Batch 142/216] [Loss: 0.2297 0.0670 -0.6865 0.2606 1.2171] Time_left: 6:11:56.101844\n",
      "[Epoch 2/200] [Batch 143/216] [Loss: 0.2341 0.0843 -0.6252 0.3219 0.9973] Time_left: 6:11:02.143403\n",
      "[Epoch 2/200] [Batch 144/216] [Loss: 0.2623 0.0958 -0.6698 0.3183 0.7793] Time_left: 6:10:50.279938\n",
      "[Epoch 2/200] [Batch 145/216] [Loss: 0.3066 0.1020 -0.6396 0.3218 1.0970] Time_left: 6:11:00.224903\n",
      "[Epoch 2/200] [Batch 146/216] [Loss: 0.3205 0.0844 -0.6687 0.2535 0.9428] Time_left: 6:10:18.750282\n",
      "[Epoch 2/200] [Batch 147/216] [Loss: 0.3319 0.0935 -0.6109 0.3024 0.6402] Time_left: 6:11:24.005269\n",
      "[Epoch 2/200] [Batch 148/216] [Loss: 0.3696 0.0742 -0.6512 0.2115 0.9710] Time_left: 6:11:38.978562\n",
      "[Epoch 2/200] [Batch 149/216] [Loss: 0.6377 0.1048 -0.6429 0.3449 0.6377] Time_left: 6:14:18.524134\n",
      "[Epoch 2/200] [Batch 150/216] [Loss: 0.3135 0.0981 -0.6351 0.3744 0.9421] Time_left: 6:08:57.867133\n",
      "[Epoch 2/200] [Batch 151/216] [Loss: 0.3292 0.0801 -0.7190 0.3051 0.4345] Time_left: 6:17:48.578757\n",
      "[Epoch 2/200] [Batch 152/216] [Loss: 0.2542 0.1005 -0.6799 0.3176 0.2596] Time_left: 6:14:33.768951\n",
      "[Epoch 2/200] [Batch 153/216] [Loss: 0.2485 0.0743 -0.6926 0.1899 0.9462] Time_left: 6:12:18.354678\n",
      "[Epoch 2/200] [Batch 154/216] [Loss: 0.2245 0.0975 -0.6774 0.3149 0.2263] Time_left: 6:12:35.366595\n",
      "[Epoch 2/200] [Batch 155/216] [Loss: 0.4246 0.0909 -0.6557 0.2919 0.6002] Time_left: 6:10:51.741045\n",
      "[Epoch 2/200] [Batch 156/216] [Loss: 0.1788 0.0813 -0.6709 0.3466 0.2197] Time_left: 6:13:54.841530\n",
      "[Epoch 2/200] [Batch 157/216] [Loss: 0.1561 0.0915 -0.6793 0.2909 0.5795] Time_left: 6:11:39.857311\n",
      "[Epoch 2/200] [Batch 158/216] [Loss: 0.1760 0.0854 -0.7137 0.2924 0.2871] Time_left: 6:15:15.599101\n",
      "[Epoch 2/200] [Batch 159/216] [Loss: 0.1668 0.0816 -0.7063 0.2596 0.2339] Time_left: 6:13:04.276433\n",
      "[Epoch 2/200] [Batch 160/216] [Loss: 0.1394 0.0930 -0.7003 0.3212 1.0988] Time_left: 6:13:09.764946\n",
      "[Epoch 2/200] [Batch 161/216] [Loss: 0.2499 0.1022 -0.6353 0.3745 0.2503] Time_left: 6:13:42.528214\n",
      "[Epoch 2/200] [Batch 162/216] [Loss: 0.1806 0.0969 -0.6731 0.3725 0.1809] Time_left: 6:12:38.178846\n",
      "[Epoch 2/200] [Batch 163/216] [Loss: 0.1334 0.1162 -0.6362 0.3134 0.1536] Time_left: 6:14:10.141064\n",
      "[Epoch 2/200] [Batch 164/216] [Loss: 0.1101 0.0971 -0.6979 0.2715 0.6791] Time_left: 6:12:16.377368\n",
      "[Epoch 2/200] [Batch 165/216] [Loss: 0.2915 0.0812 -0.7442 0.2339 0.7451] Time_left: 6:10:09.383965\n",
      "[Epoch 2/200] [Batch 166/216] [Loss: 0.1301 0.1044 -0.6511 0.3501 0.2057] Time_left: 6:14:58.888725\n",
      "[Epoch 2/200] [Batch 167/216] [Loss: 0.1416 0.0952 -0.6971 0.2338 0.1441] Time_left: 6:11:25.503085\n",
      "[Epoch 2/200] [Batch 168/216] [Loss: 0.1630 0.0859 -0.6622 0.2822 0.6372] Time_left: 6:15:22.096682\n",
      "[Epoch 2/200] [Batch 169/216] [Loss: 0.1457 0.0762 -0.7151 0.2509 0.1500] Time_left: 6:12:03.975367\n",
      "[Epoch 2/200] [Batch 170/216] [Loss: 0.0803 0.0939 -0.6638 0.2547 0.3159] Time_left: 6:11:49.781134\n",
      "[Epoch 2/200] [Batch 171/216] [Loss: 0.0864 0.1159 -0.6457 0.2945 0.0875] Time_left: 6:13:18.527909\n",
      "[Epoch 2/200] [Batch 172/216] [Loss: 0.0647 0.1039 -0.6499 0.2640 0.0692] Time_left: 6:13:35.083935\n",
      "[Epoch 2/200] [Batch 173/216] [Loss: 0.0448 0.0747 -0.7617 0.1925 0.0535] Time_left: 6:14:16.052835\n",
      "[Epoch 2/200] [Batch 174/216] [Loss: 0.0308 0.0907 -0.6707 0.3126 0.0308] Time_left: 6:11:28.888943\n",
      "[Epoch 2/200] [Batch 175/216] [Loss: 0.0174 0.0878 -0.6738 0.3344 0.0174] Time_left: 6:12:28.198695\n",
      "[Epoch 2/200] [Batch 176/216] [Loss: 0.0217 0.0951 -0.7114 0.2120 0.7410] Time_left: 6:15:30.083313\n",
      "[Epoch 2/200] [Batch 177/216] [Loss: 0.4919 0.0803 -0.7152 0.3382 0.5798] Time_left: 6:12:35.597844\n",
      "[Epoch 2/200] [Batch 178/216] [Loss: 0.0700 0.0713 -0.7167 0.1892 0.7210] Time_left: 6:09:37.617328\n",
      "[Epoch 2/200] [Batch 179/216] [Loss: 0.1337 0.0820 -0.6590 0.2417 0.5262] Time_left: 6:11:46.113441\n",
      "[Epoch 2/200] [Batch 180/216] [Loss: 0.1810 0.0868 -0.6360 0.2780 0.2657] Time_left: 6:14:05.478184\n",
      "[Epoch 2/200] [Batch 181/216] [Loss: 0.1640 0.0957 -0.6635 0.2860 0.1706] Time_left: 6:16:56.251385\n",
      "[Epoch 2/200] [Batch 182/216] [Loss: 0.1374 0.1074 -0.5443 0.3527 0.1439] Time_left: 6:08:27.415987\n",
      "[Epoch 2/200] [Batch 183/216] [Loss: 0.0801 0.0839 -0.7370 0.2388 0.0911] Time_left: 6:14:43.290925\n",
      "[Epoch 2/200] [Batch 184/216] [Loss: 0.0804 0.0983 -0.6639 0.3211 0.0810] Time_left: 6:12:22.938370\n",
      "[Epoch 2/200] [Batch 185/216] [Loss: 0.0730 0.0701 -0.7010 0.1968 0.6481] Time_left: 6:11:09.944586\n",
      "[Epoch 2/200] [Batch 186/216] [Loss: 6.5838 0.0701 -0.7058 0.2048 6.5914] Time_left: 6:08:47.075651\n",
      "[Epoch 2/200] [Batch 187/216] [Loss: 0.1335 0.1264 -0.6344 0.4598 0.2276] Time_left: 6:11:20.147160\n",
      "[Epoch 2/200] [Batch 188/216] [Loss: 0.1517 0.0986 -0.6464 0.4014 1.8208] Time_left: 6:13:35.171595\n",
      "[Epoch 2/200] [Batch 189/216] [Loss: 0.2817 0.0775 -0.6928 0.2143 1.6325] Time_left: 6:09:51.705340\n",
      "[Epoch 2/200] [Batch 190/216] [Loss: 0.3860 0.1138 -0.6097 0.4070 1.3146] Time_left: 6:16:57.735250\n",
      "[Epoch 2/200] [Batch 191/216] [Loss: 0.5189 0.1123 -0.6303 0.3802 0.8115] Time_left: 6:13:35.145446\n",
      "[Epoch 2/200] [Batch 192/216] [Loss: 0.5539 0.1050 -0.6709 0.2906 1.0831] Time_left: 6:12:33.520660\n",
      "[Epoch 2/200] [Batch 193/216] [Loss: 0.6413 0.0975 -0.6288 0.3740 0.9609] Time_left: 6:13:53.723921\n",
      "[Epoch 2/200] [Batch 194/216] [Loss: 0.6661 0.0965 -0.7167 0.2746 0.9646] Time_left: 6:12:41.595847\n",
      "[Epoch 2/200] [Batch 195/216] [Loss: 0.6764 0.1178 -0.6873 0.2122 1.1747] Time_left: 6:12:58.153383\n",
      "[Epoch 2/200] [Batch 196/216] [Loss: 0.7211 0.0947 -0.6789 0.3257 0.7642] Time_left: 6:14:24.369263\n",
      "[Epoch 2/200] [Batch 197/216] [Loss: 0.5209 0.0942 -0.6379 0.3028 0.9430] Time_left: 6:05:59.014943\n",
      "[Epoch 2/200] [Batch 198/216] [Loss: 0.3790 0.0672 -0.6710 0.2134 1.0030] Time_left: 6:12:09.107344\n",
      "[Epoch 2/200] [Batch 199/216] [Loss: 0.6372 0.0839 -0.7274 0.2418 0.7628] Time_left: 6:15:37.829709\n",
      "[Epoch 2/200] [Batch 200/216] [Loss: 0.3245 0.1029 -0.6461 0.3589 0.7509] Time_left: 6:11:22.966274\n",
      "[Epoch 2/200] [Batch 201/216] [Loss: 0.2186 0.0889 -0.7395 0.2427 1.6251] Time_left: 6:14:30.184786\n",
      "[Epoch 2/200] [Batch 202/216] [Loss: 0.3451 0.1193 -0.6207 0.3316 0.5823] Time_left: 6:08:38.071399\n",
      "[Epoch 2/200] [Batch 203/216] [Loss: 0.3942 0.1194 -0.6339 0.3547 0.6266] Time_left: 6:17:38.739620\n",
      "[Epoch 2/200] [Batch 204/216] [Loss: 0.4488 0.1087 -0.6799 0.3346 0.8330] Time_left: 6:12:50.916038\n",
      "[Epoch 2/200] [Batch 205/216] [Loss: 0.5504 0.0753 -0.7309 0.2670 1.0495] Time_left: 6:13:56.117820\n",
      "[Epoch 2/200] [Batch 206/216] [Loss: 0.2999 0.0782 -0.7183 0.2593 1.2690] Time_left: 6:11:07.831039\n",
      "[Epoch 2/200] [Batch 207/216] [Loss: 0.3171 0.0760 -0.6991 0.2765 1.2559] Time_left: 6:15:27.749306\n",
      "[Epoch 2/200] [Batch 208/216] [Loss: 0.3453 0.0757 -0.6944 0.2120 1.6374] Time_left: 6:13:58.991013\n",
      "[Epoch 2/200] [Batch 209/216] [Loss: 0.3952 0.0915 -0.7307 0.2159 0.9553] Time_left: 6:11:46.808320\n",
      "[Epoch 2/200] [Batch 210/216] [Loss: 0.4065 0.0848 -0.6798 0.2723 0.9341] Time_left: 6:11:30.587364\n",
      "[Epoch 2/200] [Batch 211/216] [Loss: 0.4463 0.0519 -0.7934 0.1356 1.4575] Time_left: 6:16:26.987243\n",
      "[Epoch 2/200] [Batch 212/216] [Loss: 0.4739 0.0804 -0.7539 0.2337 0.7760] Time_left: 6:13:21.877898\n",
      "[Epoch 2/200] [Batch 213/216] [Loss: 0.4708 0.0980 -0.6721 0.3055 0.8873] Time_left: 6:13:11.580985\n",
      "[Epoch 2/200] [Batch 214/216] [Loss: 0.4452 0.0919 -0.7138 0.2683 0.4871] Time_left: 6:11:12.634612\n",
      "[Epoch 2/200] [Batch 215/216] [Loss: 0.4210 0.1291 -0.6424 0.4184 1.2525] Time_left: 3:43:48.384130\n",
      "[Epoch 3/200] [Batch 0/216] [Loss: 1.1258 0.0966 -0.6525 0.3474 1.3296] Time_left: 8:22:03.638203\n",
      "[Epoch 3/200] [Batch 1/216] [Loss: 0.3683 0.0687 -0.7364 0.2184 0.9753] Time_left: 6:23:48.334136\n",
      "[Epoch 3/200] [Batch 2/216] [Loss: 0.3508 0.1260 -0.6342 0.3086 1.4169] Time_left: 6:07:53.895955\n",
      "[Epoch 3/200] [Batch 3/216] [Loss: 0.3702 0.0640 -0.7700 0.1769 1.5442] Time_left: 6:12:53.369509\n",
      "[Epoch 3/200] [Batch 4/216] [Loss: 0.3939 0.0922 -0.6826 0.3063 1.3510] Time_left: 6:10:20.051235\n",
      "[Epoch 3/200] [Batch 5/216] [Loss: 0.4276 0.0954 -0.6717 0.2395 1.0684] Time_left: 6:10:14.162827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 6/216] [Loss: 0.4724 0.0761 -0.6838 0.2458 1.0105] Time_left: 6:15:24.414997\n",
      "[Epoch 3/200] [Batch 7/216] [Loss: 0.4226 0.0581 -0.7570 0.2276 1.4913] Time_left: 6:15:44.284199\n",
      "[Epoch 3/200] [Batch 8/216] [Loss: 0.4802 0.1144 -0.6232 0.3474 1.0900] Time_left: 6:10:47.398094\n",
      "[Epoch 3/200] [Batch 9/216] [Loss: 0.4812 0.0942 -0.6211 0.4211 1.1801] Time_left: 6:08:27.459060\n",
      "[Epoch 3/200] [Batch 10/216] [Loss: 0.4572 0.0630 -0.6923 0.2170 1.3843] Time_left: 6:13:30.057084\n",
      "[Epoch 3/200] [Batch 11/216] [Loss: 0.4802 0.1362 -0.6299 0.4011 0.7417] Time_left: 6:09:05.336782\n",
      "[Epoch 3/200] [Batch 12/216] [Loss: 0.4776 0.0725 -0.7849 0.1934 0.7086] Time_left: 6:16:01.483269\n",
      "[Epoch 3/200] [Batch 13/216] [Loss: 0.4580 0.1254 -0.6396 0.2737 1.3212] Time_left: 6:15:09.116698\n",
      "[Epoch 3/200] [Batch 14/216] [Loss: 0.4458 0.1081 -0.6243 0.2844 0.8215] Time_left: 6:12:51.175638\n",
      "[Epoch 3/200] [Batch 15/216] [Loss: 0.4471 0.0854 -0.7200 0.2268 0.6837] Time_left: 6:15:22.550779\n",
      "[Epoch 3/200] [Batch 16/216] [Loss: 0.4173 0.0942 -0.6807 0.2978 1.2174] Time_left: 6:09:38.512722\n",
      "[Epoch 3/200] [Batch 17/216] [Loss: 0.4300 0.1058 -0.6456 0.3459 1.2127] Time_left: 6:13:08.125759\n",
      "[Epoch 3/200] [Batch 18/216] [Loss: 0.4127 0.0837 -0.6111 0.3241 1.2219] Time_left: 6:15:10.436085\n",
      "[Epoch 3/200] [Batch 19/216] [Loss: 0.4533 0.0936 -0.6520 0.3210 1.0174] Time_left: 6:12:17.759050\n",
      "[Epoch 3/200] [Batch 20/216] [Loss: 0.4300 0.1004 -0.6188 0.3785 0.9561] Time_left: 6:13:51.164565\n",
      "[Epoch 3/200] [Batch 21/216] [Loss: 0.4565 0.1072 -0.6839 0.3222 1.1921] Time_left: 6:14:06.121226\n",
      "[Epoch 3/200] [Batch 22/216] [Loss: 0.4676 0.0650 -0.7297 0.2083 1.0300] Time_left: 6:12:34.171748\n",
      "[Epoch 3/200] [Batch 23/216] [Loss: 0.4445 0.0924 -0.6713 0.3259 0.7192] Time_left: 6:12:01.391741\n",
      "[Epoch 3/200] [Batch 24/216] [Loss: 0.4225 0.1028 -0.7009 0.3227 0.6144] Time_left: 6:15:47.605614\n",
      "[Epoch 3/200] [Batch 25/216] [Loss: 0.4167 0.0883 -0.6941 0.2804 1.2262] Time_left: 6:11:48.012739\n",
      "[Epoch 3/200] [Batch 26/216] [Loss: 0.4060 0.0715 -0.7365 0.2157 0.6138] Time_left: 6:12:29.321644\n",
      "[Epoch 3/200] [Batch 27/216] [Loss: 0.4137 0.0772 -0.7530 0.2225 0.9183] Time_left: 6:13:34.282286\n",
      "[Epoch 3/200] [Batch 28/216] [Loss: 0.5236 0.0804 -0.7092 0.2786 0.7876] Time_left: 6:11:56.040226\n",
      "[Epoch 3/200] [Batch 29/216] [Loss: 0.3686 0.0951 -0.6392 0.3568 0.4760] Time_left: 6:13:14.715630\n",
      "[Epoch 3/200] [Batch 30/216] [Loss: 0.3398 0.0769 -0.7081 0.2267 0.3474] Time_left: 6:15:05.940538\n",
      "[Epoch 3/200] [Batch 31/216] [Loss: 0.3060 0.1072 -0.6383 0.3131 0.6942] Time_left: 6:11:22.805527\n",
      "[Epoch 3/200] [Batch 32/216] [Loss: 0.3119 0.0695 -0.6808 0.3028 0.8764] Time_left: 6:12:01.990299\n",
      "[Epoch 3/200] [Batch 33/216] [Loss: 1.0829 0.0776 -0.7462 0.2541 1.7321] Time_left: 6:14:40.651652\n",
      "[Epoch 3/200] [Batch 34/216] [Loss: 0.2483 0.0670 -0.7026 0.1741 1.0736] Time_left: 6:12:21.001630\n",
      "[Epoch 3/200] [Batch 35/216] [Loss: 0.2621 0.0572 -0.7170 0.2194 1.4545] Time_left: 6:11:17.120915\n",
      "[Epoch 3/200] [Batch 36/216] [Loss: 0.3014 0.1056 -0.6444 0.3329 0.6856] Time_left: 6:14:22.634056\n",
      "[Epoch 3/200] [Batch 37/216] [Loss: 0.3330 0.0613 -0.7120 0.1913 1.4585] Time_left: 6:13:52.061534\n",
      "[Epoch 3/200] [Batch 38/216] [Loss: 0.3686 0.0803 -0.7202 0.3114 1.4129] Time_left: 6:14:07.265177\n",
      "[Epoch 3/200] [Batch 39/216] [Loss: 0.4298 0.1073 -0.6381 0.3502 1.1966] Time_left: 6:13:56.935775\n",
      "[Epoch 3/200] [Batch 40/216] [Loss: 0.4458 0.0932 -0.6855 0.2408 1.1186] Time_left: 6:12:17.098904\n",
      "[Epoch 3/200] [Batch 41/216] [Loss: 0.4627 0.0868 -0.7202 0.2474 1.0283] Time_left: 6:14:55.456195\n",
      "[Epoch 3/200] [Batch 42/216] [Loss: 0.4679 0.0731 -0.6892 0.2435 0.8165] Time_left: 6:11:41.760750\n",
      "[Epoch 3/200] [Batch 43/216] [Loss: 0.4537 0.1125 -0.6195 0.3611 1.0368] Time_left: 6:11:58.070254\n",
      "[Epoch 3/200] [Batch 44/216] [Loss: 0.4512 0.0871 -0.7602 0.2176 0.8648] Time_left: 6:16:12.726768\n",
      "[Epoch 3/200] [Batch 45/216] [Loss: 0.4183 0.0819 -0.6938 0.2442 0.9048] Time_left: 6:11:11.759722\n",
      "[Epoch 3/200] [Batch 46/216] [Loss: 0.4181 0.1109 -0.6884 0.3585 0.6943] Time_left: 6:16:16.762235\n",
      "[Epoch 3/200] [Batch 47/216] [Loss: 0.4157 0.0578 -0.7196 0.1853 1.3006] Time_left: 6:11:23.490763\n",
      "[Epoch 3/200] [Batch 48/216] [Loss: 0.4029 0.0986 -0.6594 0.3527 0.9546] Time_left: 6:10:48.420576\n",
      "[Epoch 3/200] [Batch 49/216] [Loss: 0.3903 0.1229 -0.6020 0.3782 0.4701] Time_left: 6:14:43.865927\n",
      "[Epoch 3/200] [Batch 50/216] [Loss: 0.3535 0.0759 -0.7502 0.2093 1.0285] Time_left: 6:13:41.828005\n",
      "[Epoch 3/200] [Batch 51/216] [Loss: 0.3667 0.1342 -0.5902 0.3255 0.3667] Time_left: 6:11:44.507177\n",
      "[Epoch 3/200] [Batch 52/216] [Loss: 0.3356 0.1167 -0.6058 0.4260 0.5761] Time_left: 6:15:05.665421\n",
      "[Epoch 3/200] [Batch 53/216] [Loss: 0.3120 0.0979 -0.6825 0.2597 0.5890] Time_left: 6:12:19.803039\n",
      "[Epoch 3/200] [Batch 54/216] [Loss: 1.1520 0.0977 -0.6863 0.3022 1.3979] Time_left: 6:11:05.017663\n",
      "[Epoch 3/200] [Batch 55/216] [Loss: 0.2776 0.0719 -0.7575 0.1513 0.7301] Time_left: 6:14:37.135601\n",
      "[Epoch 3/200] [Batch 56/216] [Loss: 0.2907 0.0643 -0.7511 0.2536 0.8820] Time_left: 6:12:49.796875\n",
      "[Epoch 3/200] [Batch 57/216] [Loss: 0.3307 0.0840 -0.7968 0.1862 0.7048] Time_left: 6:12:26.778331\n",
      "[Epoch 3/200] [Batch 58/216] [Loss: 0.3259 0.0677 -0.6411 0.2503 0.8321] Time_left: 6:14:30.199510\n",
      "[Epoch 3/200] [Batch 59/216] [Loss: 0.3137 0.0567 -0.7888 0.2034 0.9109] Time_left: 6:12:35.422076\n",
      "[Epoch 3/200] [Batch 60/216] [Loss: 0.3120 0.0728 -0.6582 0.2954 0.9349] Time_left: 6:10:22.870322\n",
      "[Epoch 3/200] [Batch 61/216] [Loss: 0.3055 0.1445 -0.5558 0.4140 0.3066] Time_left: 6:13:11.387256\n",
      "[Epoch 3/200] [Batch 62/216] [Loss: 0.2558 0.0788 -0.6875 0.3021 0.5151] Time_left: 6:13:59.131670\n",
      "[Epoch 3/200] [Batch 63/216] [Loss: 0.2569 0.0759 -0.7011 0.3292 0.6092] Time_left: 6:11:56.849089\n",
      "[Epoch 3/200] [Batch 64/216] [Loss: 0.2518 0.0872 -0.6206 0.3554 0.2609] Time_left: 6:16:12.398315\n",
      "[Epoch 3/200] [Batch 65/216] [Loss: 0.1930 0.0976 -0.6529 0.3268 0.3174] Time_left: 6:11:17.680588\n",
      "[Epoch 3/200] [Batch 66/216] [Loss: 1.0681 0.0899 -0.7134 0.3548 1.3511] Time_left: 6:11:15.778642\n",
      "[Epoch 3/200] [Batch 67/216] [Loss: 0.1093 0.0806 -0.7134 0.2421 0.7734] Time_left: 6:16:02.447919\n",
      "[Epoch 3/200] [Batch 68/216] [Loss: 0.1357 0.1676 -0.5565 0.3726 0.8679] Time_left: 6:11:25.608543\n",
      "[Epoch 3/200] [Batch 69/216] [Loss: 0.1835 0.0993 -0.6327 0.2864 1.1037] Time_left: 6:11:00.369862\n",
      "[Epoch 3/200] [Batch 70/216] [Loss: 0.3025 0.1303 -0.6159 0.3953 0.6184] Time_left: 6:12:29.614757\n",
      "[Epoch 3/200] [Batch 71/216] [Loss: 0.3103 0.1094 -0.6547 0.3620 0.7397] Time_left: 6:13:35.692096\n",
      "[Epoch 3/200] [Batch 72/216] [Loss: 0.3369 0.1023 -0.7036 0.2147 1.0795] Time_left: 6:14:03.755836\n",
      "[Epoch 3/200] [Batch 73/216] [Loss: 0.3867 0.0979 -0.6435 0.2969 0.9487] Time_left: 6:14:37.824006\n",
      "[Epoch 3/200] [Batch 74/216] [Loss: 0.2663 0.0909 -0.6392 0.3523 0.5891] Time_left: 6:12:02.910567\n",
      "[Epoch 3/200] [Batch 75/216] [Loss: 0.2187 0.0833 -0.6846 0.2816 0.4884] Time_left: 6:12:30.721252\n",
      "[Epoch 3/200] [Batch 76/216] [Loss: 0.3637 0.0729 -0.7187 0.2966 1.0387] Time_left: 6:13:21.741842\n",
      "[Epoch 3/200] [Batch 77/216] [Loss: 0.2501 0.0946 -0.6843 0.2154 0.5027] Time_left: 6:11:39.814504\n",
      "[Epoch 3/200] [Batch 78/216] [Loss: 0.3904 0.1047 -0.6066 0.3273 0.7980] Time_left: 6:11:10.124913\n",
      "[Epoch 3/200] [Batch 79/216] [Loss: 0.3405 0.1072 -0.6062 0.3791 0.3691] Time_left: 6:13:20.807736\n",
      "[Epoch 3/200] [Batch 80/216] [Loss: 0.1597 0.0962 -0.6816 0.2528 0.6462] Time_left: 6:12:55.653614\n",
      "[Epoch 3/200] [Batch 81/216] [Loss: 0.1447 0.0984 -0.6641 0.2595 0.4293] Time_left: 6:11:36.701875\n",
      "[Epoch 3/200] [Batch 82/216] [Loss: 0.2562 0.0832 -0.6634 0.2657 1.1524] Time_left: 6:13:27.751284\n",
      "[Epoch 3/200] [Batch 83/216] [Loss: 0.9024 0.0829 -0.7154 0.3062 0.9264] Time_left: 6:13:10.344630\n",
      "[Epoch 3/200] [Batch 84/216] [Loss: 0.1133 0.0933 -0.5523 0.3079 0.5897] Time_left: 6:11:41.293139\n",
      "[Epoch 3/200] [Batch 85/216] [Loss: 0.1448 0.0895 -0.6103 0.3574 0.7191] Time_left: 6:15:41.245024\n",
      "[Epoch 3/200] [Batch 86/216] [Loss: 0.1340 0.0953 -0.6289 0.3351 1.0675] Time_left: 6:10:36.862357\n",
      "[Epoch 3/200] [Batch 87/216] [Loss: 0.4820 0.0931 -0.7599 0.2030 0.7284] Time_left: 6:11:51.522846\n",
      "[Epoch 3/200] [Batch 88/216] [Loss: 0.3311 0.0658 -0.6899 0.2384 0.6924] Time_left: 6:12:21.208069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 89/216] [Loss: 0.3838 0.0717 -0.7627 0.2725 0.9001] Time_left: 6:14:03.106133\n",
      "[Epoch 3/200] [Batch 90/216] [Loss: 0.2486 0.1182 -0.6819 0.2771 0.2561] Time_left: 6:10:34.210995\n",
      "[Epoch 3/200] [Batch 91/216] [Loss: 0.2270 0.1161 -0.6572 0.2801 0.2808] Time_left: 6:11:39.996237\n",
      "[Epoch 3/200] [Batch 92/216] [Loss: 0.1123 0.0723 -0.6804 0.2542 0.2972] Time_left: 6:14:07.361650\n",
      "[Epoch 3/200] [Batch 93/216] [Loss: 0.0873 0.1108 -0.6566 0.2402 0.6529] Time_left: 6:12:57.125902\n",
      "[Epoch 3/200] [Batch 94/216] [Loss: 0.1134 0.0865 -0.7047 0.2933 0.1253] Time_left: 6:13:35.622175\n",
      "[Epoch 3/200] [Batch 95/216] [Loss: 0.3261 0.0763 -0.7571 0.1890 0.5725] Time_left: 6:13:31.612074\n",
      "[Epoch 3/200] [Batch 96/216] [Loss: 0.3032 0.0727 -0.6566 0.2209 1.3899] Time_left: 6:10:22.313450\n",
      "[Epoch 3/200] [Batch 97/216] [Loss: 0.1641 0.1190 -0.6816 0.3499 0.1641] Time_left: 6:11:12.369968\n",
      "[Epoch 3/200] [Batch 98/216] [Loss: 0.0969 0.0935 -0.6709 0.2669 0.0969] Time_left: 6:15:09.050263\n",
      "[Epoch 3/200] [Batch 99/216] [Loss: 0.1569 0.0866 -0.7108 0.2474 0.5224] Time_left: 6:10:12.898963\n",
      "[Epoch 3/200] [Batch 100/216] [Loss: 0.1239 0.0978 -0.7245 0.2939 0.1239] Time_left: 6:16:00.367829\n",
      "[Epoch 3/200] [Batch 101/216] [Loss: 0.3143 0.0777 -0.7445 0.2612 0.9359] Time_left: 6:11:17.336056\n",
      "[Epoch 3/200] [Batch 102/216] [Loss: 0.1932 0.0848 -0.6712 0.2144 0.4009] Time_left: 6:11:06.538596\n",
      "[Epoch 3/200] [Batch 103/216] [Loss: 0.1236 0.1012 -0.6194 0.3403 0.1236] Time_left: 6:11:45.312468\n",
      "[Epoch 3/200] [Batch 104/216] [Loss: 0.0630 0.0858 -0.6820 0.2081 0.6922] Time_left: 6:14:25.225578\n",
      "[Epoch 3/200] [Batch 105/216] [Loss: 0.1938 0.0929 -0.7333 0.2422 1.0176] Time_left: 6:10:58.842296\n",
      "[Epoch 3/200] [Batch 106/216] [Loss: 0.1189 0.0805 -0.6633 0.2609 0.7244] Time_left: 6:12:47.582627\n",
      "[Epoch 3/200] [Batch 107/216] [Loss: 0.2270 0.0799 -0.7165 0.2392 0.3140] Time_left: 6:15:08.326347\n",
      "[Epoch 3/200] [Batch 108/216] [Loss: 0.2464 0.0778 -0.7024 0.1660 0.8244] Time_left: 6:09:33.743279\n",
      "[Epoch 3/200] [Batch 109/216] [Loss: 0.2587 0.0866 -0.6039 0.3307 0.4252] Time_left: 6:12:02.226072\n",
      "[Epoch 3/200] [Batch 110/216] [Loss: 0.3415 0.0935 -0.7008 0.2056 0.4156] Time_left: 6:15:46.371437\n",
      "[Epoch 3/200] [Batch 111/216] [Loss: 0.1668 0.0937 -0.6403 0.3459 0.1668] Time_left: 6:09:43.235773\n",
      "[Epoch 3/200] [Batch 112/216] [Loss: 0.0910 0.1158 -0.6690 0.3815 0.0910] Time_left: 6:14:27.700205\n",
      "[Epoch 3/200] [Batch 113/216] [Loss: 0.0554 0.1052 -0.6399 0.3301 0.0583] Time_left: 6:11:19.689824\n",
      "[Epoch 3/200] [Batch 114/216] [Loss: 0.0880 0.0818 -0.5777 0.3099 0.9931] Time_left: 6:12:18.517076\n",
      "[Epoch 3/200] [Batch 115/216] [Loss: 0.2852 0.0704 -0.7652 0.1901 0.6754] Time_left: 6:11:27.705382\n",
      "[Epoch 3/200] [Batch 116/216] [Loss: 0.4094 0.0591 -0.7694 0.1654 0.5661] Time_left: 6:13:55.219898\n",
      "[Epoch 3/200] [Batch 117/216] [Loss: 0.2124 0.0871 -0.6609 0.3341 0.2149] Time_left: 6:10:18.869133\n",
      "[Epoch 3/200] [Batch 118/216] [Loss: 0.1218 0.0814 -0.7081 0.2845 0.3953] Time_left: 6:12:10.978697\n",
      "[Epoch 3/200] [Batch 119/216] [Loss: 0.2790 0.0887 -0.6521 0.2416 0.3175] Time_left: 6:14:40.161082\n",
      "[Epoch 3/200] [Batch 120/216] [Loss: 0.1800 0.0885 -0.6581 0.3419 0.4686] Time_left: 6:09:35.840607\n",
      "[Epoch 3/200] [Batch 121/216] [Loss: 0.1132 0.0840 -0.7108 0.1895 0.3226] Time_left: 6:12:25.080266\n",
      "[Epoch 3/200] [Batch 122/216] [Loss: 0.0977 0.1060 -0.7025 0.2580 0.3146] Time_left: 6:14:44.570589\n",
      "[Epoch 3/200] [Batch 123/216] [Loss: 0.1249 0.0954 -0.6814 0.2460 0.1249] Time_left: 6:10:45.731193\n",
      "[Epoch 3/200] [Batch 124/216] [Loss: 0.2749 0.0778 -0.7231 0.2175 0.3916] Time_left: 6:12:14.457034\n",
      "[Epoch 3/200] [Batch 125/216] [Loss: 0.5513 0.0797 -0.7401 0.1865 0.5815] Time_left: 6:12:45.753627\n",
      "[Epoch 3/200] [Batch 126/216] [Loss: 0.0793 0.0553 -0.7893 0.1896 1.2744] Time_left: 6:11:36.625544\n",
      "[Epoch 3/200] [Batch 127/216] [Loss: 0.3423 0.0681 -0.6780 0.2264 0.5165] Time_left: 6:12:34.746240\n",
      "[Epoch 3/200] [Batch 128/216] [Loss: 0.0705 0.0739 -0.7186 0.2322 0.0705] Time_left: 6:14:21.829288\n",
      "[Epoch 3/200] [Batch 129/216] [Loss: 0.1468 0.0989 -0.6054 0.4353 0.4120] Time_left: 6:10:20.859565\n",
      "[Epoch 3/200] [Batch 130/216] [Loss: 0.1616 0.0934 -0.6635 0.2983 0.1616] Time_left: 6:13:07.584067\n",
      "[Epoch 3/200] [Batch 131/216] [Loss: 0.1717 0.0764 -0.6765 0.3055 0.4037] Time_left: 6:12:06.716479\n",
      "[Epoch 3/200] [Batch 132/216] [Loss: 0.0356 0.0897 -0.7053 0.2459 1.0720] Time_left: 6:11:09.866881\n",
      "[Epoch 3/200] [Batch 133/216] [Loss: 0.1936 0.0754 -0.7257 0.2145 0.3741] Time_left: 6:15:16.110752\n",
      "[Epoch 3/200] [Batch 134/216] [Loss: 0.0835 0.0652 -0.7559 0.1752 0.7745] Time_left: 6:11:43.303057\n",
      "[Epoch 3/200] [Batch 135/216] [Loss: 0.5503 0.1311 -0.5799 0.4437 0.5503] Time_left: 6:11:40.006297\n",
      "[Epoch 3/200] [Batch 136/216] [Loss: 0.0467 0.0792 -0.6854 0.2689 0.0467] Time_left: 6:06:47.070038\n",
      "[Epoch 3/200] [Batch 137/216] [Loss: 0.0459 0.0773 -0.7267 0.1941 0.0592] Time_left: 6:14:18.985524\n",
      "[Epoch 3/200] [Batch 138/216] [Loss: 0.0445 0.0791 -0.6951 0.2552 0.0445] Time_left: 6:13:05.667787\n",
      "[Epoch 3/200] [Batch 139/216] [Loss: 0.0422 0.0653 -0.7402 0.2555 0.6651] Time_left: 6:11:34.161908\n",
      "[Epoch 3/200] [Batch 140/216] [Loss: 0.1718 0.0886 -0.7212 0.2551 0.3713] Time_left: 6:14:10.460306\n",
      "[Epoch 3/200] [Batch 141/216] [Loss: 0.1925 0.0697 -0.7662 0.1994 0.3479] Time_left: 6:10:42.107858\n",
      "[Epoch 3/200] [Batch 142/216] [Loss: 0.0684 0.0931 -0.6784 0.2747 0.0685] Time_left: 6:16:36.592281\n",
      "[Epoch 3/200] [Batch 143/216] [Loss: 0.1384 0.1345 -0.6132 0.3142 0.2364] Time_left: 6:10:53.283287\n",
      "[Epoch 3/200] [Batch 144/216] [Loss: 0.0443 0.0950 -0.5953 0.2987 0.0443] Time_left: 6:13:10.599844\n",
      "[Epoch 3/200] [Batch 145/216] [Loss: 0.0244 0.1023 -0.6442 0.3578 0.0244] Time_left: 6:12:40.922956\n",
      "[Epoch 3/200] [Batch 146/216] [Loss: 0.0443 0.0859 -0.6932 0.3367 0.0443] Time_left: 6:09:51.097378\n",
      "[Epoch 3/200] [Batch 147/216] [Loss: 0.0983 0.0774 -0.7554 0.2448 0.1604] Time_left: 6:14:42.716678\n",
      "[Epoch 3/200] [Batch 148/216] [Loss: 0.0218 0.0885 -0.7210 0.2049 0.0218] Time_left: 6:11:26.671104\n",
      "[Epoch 3/200] [Batch 149/216] [Loss: 0.0123 0.0692 -0.7579 0.1812 0.1568] Time_left: 6:11:38.074927\n",
      "[Epoch 3/200] [Batch 150/216] [Loss: 7.4884 0.0640 -0.8206 0.1718 7.4884] Time_left: 6:13:12.597877\n",
      "[Epoch 3/200] [Batch 151/216] [Loss: 0.0144 0.1098 -0.6824 0.2889 0.4492] Time_left: 6:10:38.996477\n",
      "[Epoch 3/200] [Batch 152/216] [Loss: 0.0243 0.1154 -0.7034 0.3349 1.9480] Time_left: 6:10:56.516457\n",
      "[Epoch 3/200] [Batch 153/216] [Loss: 0.0943 0.1491 -0.6436 0.3718 0.1061] Time_left: 6:13:09.295089\n",
      "[Epoch 3/200] [Batch 154/216] [Loss: 0.0600 0.1078 -0.6811 0.3022 0.0605] Time_left: 6:12:39.967993\n",
      "[Epoch 3/200] [Batch 155/216] [Loss: 0.0558 0.0792 -0.7421 0.1843 1.9746] Time_left: 6:09:37.017339\n",
      "[Epoch 3/200] [Batch 156/216] [Loss: 0.1236 0.1085 -0.6796 0.2854 0.1368] Time_left: 6:14:08.914807\n",
      "[Epoch 3/200] [Batch 157/216] [Loss: 0.1496 0.1080 -0.6484 0.3287 0.1496] Time_left: 6:13:25.649711\n",
      "[Epoch 3/200] [Batch 158/216] [Loss: 0.1337 0.0875 -0.6405 0.2546 1.1068] Time_left: 6:13:47.064633\n",
      "[Epoch 3/200] [Batch 159/216] [Loss: 0.1743 0.0856 -0.7238 0.1827 0.2396] Time_left: 6:10:10.805859\n",
      "[Epoch 3/200] [Batch 160/216] [Loss: 0.1624 0.1076 -0.6417 0.3098 0.2024] Time_left: 6:10:41.906862\n",
      "[Epoch 3/200] [Batch 161/216] [Loss: 0.1596 0.0983 -0.5924 0.3671 0.5107] Time_left: 6:15:09.808744\n",
      "[Epoch 3/200] [Batch 162/216] [Loss: 0.3038 0.0772 -0.8018 0.1825 0.3038] Time_left: 6:10:16.409740\n",
      "[Epoch 3/200] [Batch 163/216] [Loss: 0.7900 0.0857 -0.6849 0.2526 0.7900] Time_left: 6:10:14.834587\n",
      "[Epoch 3/200] [Batch 164/216] [Loss: 0.1203 0.0510 -0.8208 0.1250 0.6705] Time_left: 6:10:31.986062\n",
      "[Epoch 3/200] [Batch 165/216] [Loss: 0.1177 0.0628 -0.7498 0.1773 1.0442] Time_left: 6:13:31.072816\n",
      "[Epoch 3/200] [Batch 166/216] [Loss: 0.1243 0.0618 -0.7086 0.2125 1.4193] Time_left: 6:10:37.242987\n",
      "[Epoch 3/200] [Batch 167/216] [Loss: 0.1568 0.0630 -0.6821 0.2724 0.9082] Time_left: 6:10:56.747197\n",
      "[Epoch 3/200] [Batch 168/216] [Loss: 0.2356 0.0932 -0.7195 0.2451 1.0911] Time_left: 6:11:22.556065\n",
      "[Epoch 3/200] [Batch 169/216] [Loss: 0.2982 0.0831 -0.7002 0.2805 1.1722] Time_left: 6:14:21.624627\n",
      "[Epoch 3/200] [Batch 170/216] [Loss: 0.3208 0.0946 -0.6854 0.2305 0.9056] Time_left: 6:09:58.969772\n",
      "[Epoch 3/200] [Batch 171/216] [Loss: 0.3928 0.0831 -0.7535 0.2029 0.8992] Time_left: 6:15:11.804194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 172/216] [Loss: 0.3648 0.0729 -0.7339 0.2219 0.7790] Time_left: 6:11:05.589895\n",
      "[Epoch 3/200] [Batch 173/216] [Loss: 0.3553 0.1061 -0.6553 0.3371 0.8826] Time_left: 6:14:07.390130\n",
      "[Epoch 3/200] [Batch 174/216] [Loss: 0.2923 0.0419 -0.7129 0.1354 1.2165] Time_left: 6:11:40.993295\n",
      "[Epoch 3/200] [Batch 175/216] [Loss: 0.3489 0.0738 -0.7141 0.2309 0.9193] Time_left: 6:14:54.079738\n",
      "[Epoch 3/200] [Batch 176/216] [Loss: 0.3875 0.0448 -0.7434 0.1188 0.8904] Time_left: 6:10:42.766661\n",
      "[Epoch 3/200] [Batch 177/216] [Loss: 0.3877 0.0945 -0.6952 0.2716 0.9418] Time_left: 6:14:11.535255\n",
      "[Epoch 3/200] [Batch 178/216] [Loss: 0.3481 0.0955 -0.6556 0.3524 0.3481] Time_left: 6:12:01.993322\n",
      "[Epoch 3/200] [Batch 179/216] [Loss: 0.3581 0.0564 -0.7752 0.1186 0.9388] Time_left: 6:09:40.465798\n",
      "[Epoch 3/200] [Batch 180/216] [Loss: 0.3292 0.1159 -0.6197 0.3699 0.3299] Time_left: 6:14:10.834765\n",
      "[Epoch 3/200] [Batch 181/216] [Loss: 0.3279 0.0990 -0.6050 0.2679 0.5894] Time_left: 6:12:09.030001\n",
      "[Epoch 3/200] [Batch 182/216] [Loss: 0.2778 0.0821 -0.7431 0.1931 0.6377] Time_left: 6:11:34.520574\n",
      "[Epoch 3/200] [Batch 183/216] [Loss: 0.3953 0.0897 -0.6897 0.2554 0.3954] Time_left: 6:13:08.080287\n",
      "[Epoch 3/200] [Batch 184/216] [Loss: 0.2047 0.0911 -0.7091 0.2509 0.6710] Time_left: 6:09:49.616547\n",
      "[Epoch 3/200] [Batch 185/216] [Loss: 0.2109 0.1072 -0.6691 0.2614 0.5544] Time_left: 6:12:12.477641\n",
      "[Epoch 3/200] [Batch 186/216] [Loss: 0.1727 0.0948 -0.6651 0.3652 0.1727] Time_left: 6:13:51.322600\n",
      "[Epoch 3/200] [Batch 187/216] [Loss: 0.1575 0.0894 -0.6422 0.3407 0.1575] Time_left: 6:09:59.378217\n",
      "[Epoch 3/200] [Batch 188/216] [Loss: 0.1537 0.0774 -0.7376 0.2161 1.5722] Time_left: 6:12:03.583618\n",
      "[Epoch 3/200] [Batch 189/216] [Loss: 0.1441 0.1006 -0.7499 0.1967 0.1441] Time_left: 6:10:05.410400\n",
      "[Epoch 3/200] [Batch 190/216] [Loss: 0.1383 0.1157 -0.5912 0.4067 0.1383] Time_left: 6:12:03.761910\n",
      "[Epoch 3/200] [Batch 191/216] [Loss: 0.1174 0.1080 -0.6909 0.3213 0.4411] Time_left: 6:11:46.085730\n",
      "[Epoch 3/200] [Batch 192/216] [Loss: 0.1243 0.1027 -0.6670 0.3127 1.2049] Time_left: 6:15:22.878284\n",
      "[Epoch 3/200] [Batch 193/216] [Loss: 0.4876 0.0849 -0.7410 0.1709 0.6630] Time_left: 6:10:10.575026\n",
      "[Epoch 3/200] [Batch 194/216] [Loss: 0.1272 0.1019 -0.6724 0.3055 0.4120] Time_left: 6:14:16.343491\n",
      "[Epoch 3/200] [Batch 195/216] [Loss: 0.1324 0.0975 -0.7145 0.2624 0.4373] Time_left: 6:11:14.410463\n",
      "[Epoch 3/200] [Batch 196/216] [Loss: 0.1515 0.0670 -0.7319 0.1794 0.6423] Time_left: 6:14:00.933271\n",
      "[Epoch 3/200] [Batch 197/216] [Loss: 0.1286 0.0744 -0.7020 0.2133 0.5333] Time_left: 6:10:41.801783\n",
      "[Epoch 3/200] [Batch 198/216] [Loss: 0.1663 0.1044 -0.7324 0.2619 0.8337] Time_left: 6:09:06.406128\n",
      "[Epoch 3/200] [Batch 199/216] [Loss: 0.1535 0.0826 -0.6905 0.2854 0.3921] Time_left: 6:15:13.148217\n",
      "[Epoch 3/200] [Batch 200/216] [Loss: 0.1197 0.0846 -0.6846 0.2769 0.6590] Time_left: 6:10:28.331539\n",
      "[Epoch 3/200] [Batch 201/216] [Loss: 0.1182 0.0814 -0.6867 0.2966 0.5207] Time_left: 6:11:57.288656\n",
      "[Epoch 3/200] [Batch 202/216] [Loss: 0.1075 0.0782 -0.7239 0.2391 0.4753] Time_left: 6:12:33.949046\n",
      "[Epoch 3/200] [Batch 203/216] [Loss: 0.0802 0.0756 -0.6239 0.3041 0.5657] Time_left: 6:10:16.902532\n",
      "[Epoch 3/200] [Batch 204/216] [Loss: 0.2017 0.1029 -0.6306 0.4198 0.2036] Time_left: 6:12:26.996984\n",
      "[Epoch 3/200] [Batch 205/216] [Loss: 0.1413 0.1056 -0.6845 0.2580 0.1432] Time_left: 6:12:37.746866\n",
      "[Epoch 3/200] [Batch 206/216] [Loss: 0.0547 0.0933 -0.6856 0.2957 0.0597] Time_left: 6:10:17.206558\n",
      "[Epoch 3/200] [Batch 207/216] [Loss: 0.0293 0.0723 -0.6846 0.2689 0.6554] Time_left: 6:14:58.698946\n",
      "[Epoch 3/200] [Batch 208/216] [Loss: 0.0698 0.1140 -0.6475 0.3509 0.0757] Time_left: 6:09:59.479315\n",
      "[Epoch 3/200] [Batch 209/216] [Loss: 0.2749 0.0850 -0.7193 0.1916 0.5172] Time_left: 6:13:34.985613\n",
      "[Epoch 3/200] [Batch 210/216] [Loss: 0.0963 0.0667 -0.8076 0.1972 0.8308] Time_left: 6:10:29.331945\n",
      "[Epoch 3/200] [Batch 211/216] [Loss: 0.2298 0.0819 -0.7231 0.2222 0.4219] Time_left: 6:11:08.358695\n",
      "[Epoch 3/200] [Batch 212/216] [Loss: 0.1449 0.0993 -0.6846 0.2710 0.4508] Time_left: 6:12:38.623981\n",
      "[Epoch 3/200] [Batch 213/216] [Loss: 0.1755 0.0991 -0.6132 0.3775 0.3558] Time_left: 6:11:43.888958\n",
      "[Epoch 3/200] [Batch 214/216] [Loss: 0.1536 0.0815 -0.7752 0.2101 0.6474] Time_left: 6:10:02.662766\n",
      "[Epoch 3/200] [Batch 215/216] [Loss: 0.2703 0.1226 -0.5922 0.3723 0.2703] Time_left: 3:42:57.744403\n",
      "[Epoch 4/200] [Batch 0/216] [Loss: 0.2145 0.0909 -0.7101 0.2179 0.2182] Time_left: 8:17:42.098053\n",
      "[Epoch 4/200] [Batch 1/216] [Loss: 0.1353 0.0975 -0.7093 0.2679 0.1353] Time_left: 6:21:04.027355\n",
      "[Epoch 4/200] [Batch 2/216] [Loss: 0.0146 0.0911 -0.6689 0.3014 0.2682] Time_left: 6:10:08.942474\n",
      "[Epoch 4/200] [Batch 3/216] [Loss: 0.0309 0.0954 -0.6762 0.3807 0.4067] Time_left: 6:12:20.635818\n",
      "[Epoch 4/200] [Batch 4/216] [Loss: 13.3681 0.0668 -0.7311 0.1693 13.3681] Time_left: 6:09:44.982740\n",
      "[Epoch 4/200] [Batch 5/216] [Loss: 0.0831 0.0924 -0.6868 0.2450 1.2992] Time_left: 6:09:24.889318\n",
      "[Epoch 4/200] [Batch 6/216] [Loss: 0.4459 0.1337 -0.7007 0.2774 1.0609] Time_left: 6:09:50.423920\n",
      "[Epoch 4/200] [Batch 7/216] [Loss: 0.6056 0.1271 -0.6717 0.3110 1.2113] Time_left: 6:12:59.205807\n",
      "[Epoch 4/200] [Batch 8/216] [Loss: 0.6283 0.1185 -0.6491 0.2632 1.2246] Time_left: 6:11:12.481293\n",
      "[Epoch 4/200] [Batch 9/216] [Loss: 0.5371 0.1495 -0.6104 0.3157 1.0998] Time_left: 6:09:44.532066\n",
      "[Epoch 4/200] [Batch 10/216] [Loss: 0.4580 0.1114 -0.6712 0.1952 0.9133] Time_left: 6:13:04.895548\n",
      "[Epoch 4/200] [Batch 11/216] [Loss: 0.4956 0.1353 -0.6614 0.2858 0.8485] Time_left: 6:10:39.004868\n",
      "[Epoch 4/200] [Batch 12/216] [Loss: 0.2936 0.1227 -0.6053 0.3504 1.0293] Time_left: 6:10:13.666088\n",
      "[Epoch 4/200] [Batch 13/216] [Loss: 0.3596 0.1063 -0.6597 0.2458 0.9873] Time_left: 6:11:35.389635\n",
      "[Epoch 4/200] [Batch 14/216] [Loss: 0.2997 0.1057 -0.6530 0.2514 0.6787] Time_left: 6:12:51.640326\n",
      "[Epoch 4/200] [Batch 15/216] [Loss: 0.2745 0.1134 -0.6362 0.3099 0.8675] Time_left: 6:09:43.909859\n",
      "[Epoch 4/200] [Batch 16/216] [Loss: 0.2848 0.1240 -0.6881 0.2428 0.5434] Time_left: 6:09:51.296139\n",
      "[Epoch 4/200] [Batch 17/216] [Loss: 0.1175 0.1046 -0.6337 0.2863 0.4054] Time_left: 6:12:33.114011\n",
      "[Epoch 4/200] [Batch 18/216] [Loss: 0.2919 0.1118 -0.6911 0.2415 0.4587] Time_left: 6:12:48.446338\n",
      "[Epoch 4/200] [Batch 19/216] [Loss: 0.0484 0.0956 -0.6363 0.2735 0.4064] Time_left: 6:12:20.475246\n",
      "[Epoch 4/200] [Batch 20/216] [Loss: 0.3574 0.1137 -0.7155 0.2675 0.4366] Time_left: 6:11:57.136265\n",
      "[Epoch 4/200] [Batch 21/216] [Loss: 0.0202 0.1184 -0.6786 0.2878 0.1157] Time_left: 6:07:58.808545\n",
      "[Epoch 4/200] [Batch 22/216] [Loss: 0.0103 0.1179 -0.7289 0.2233 0.9517] Time_left: 6:10:47.126967\n",
      "[Epoch 4/200] [Batch 23/216] [Loss: 0.9648 0.1134 -0.7222 0.2554 0.9867] Time_left: 6:11:33.602153\n",
      "[Epoch 4/200] [Batch 24/216] [Loss: 0.0141 0.0884 -0.6441 0.2997 2.1474] Time_left: 6:11:57.215784\n",
      "[Epoch 4/200] [Batch 25/216] [Loss: 0.0753 0.0906 -0.7091 0.3100 0.7381] Time_left: 6:08:53.071506\n",
      "[Epoch 4/200] [Batch 26/216] [Loss: 0.8055 0.1097 -0.6497 0.2864 0.8205] Time_left: 6:09:22.024047\n",
      "[Epoch 4/200] [Batch 27/216] [Loss: 0.1169 0.0986 -0.6684 0.3273 0.5797] Time_left: 6:07:25.224496\n",
      "[Epoch 4/200] [Batch 28/216] [Loss: 0.1423 0.1068 -0.6400 0.3288 0.2046] Time_left: 6:15:02.714367\n",
      "[Epoch 4/200] [Batch 29/216] [Loss: 0.0980 0.0932 -0.6438 0.2611 0.1202] Time_left: 6:10:53.331667\n",
      "[Epoch 4/200] [Batch 30/216] [Loss: 0.1296 0.0773 -0.7314 0.2250 0.2831] Time_left: 6:10:09.443650\n",
      "[Epoch 4/200] [Batch 31/216] [Loss: 0.0613 0.1025 -0.6793 0.2880 0.2621] Time_left: 6:09:30.489883\n",
      "[Epoch 4/200] [Batch 32/216] [Loss: 0.0807 0.0835 -0.7442 0.2482 0.2260] Time_left: 6:13:21.925018\n",
      "[Epoch 4/200] [Batch 33/216] [Loss: 0.1398 0.0947 -0.6267 0.2045 0.2753] Time_left: 6:10:56.058789\n",
      "[Epoch 4/200] [Batch 34/216] [Loss: 0.1301 0.1049 -0.7154 0.1796 0.1323] Time_left: 6:08:27.072901\n",
      "[Epoch 4/200] [Batch 35/216] [Loss: 0.3309 0.0968 -0.6487 0.3117 1.2067] Time_left: 6:09:46.718702\n",
      "[Epoch 4/200] [Batch 36/216] [Loss: 0.0255 0.0726 -0.7853 0.2088 1.3496] Time_left: 6:09:47.767482\n",
      "[Epoch 4/200] [Batch 37/216] [Loss: 0.6813 0.1071 -0.6987 0.2430 0.6829] Time_left: 6:11:10.392681\n",
      "[Epoch 4/200] [Batch 38/216] [Loss: 0.0429 0.0928 -0.7051 0.2643 0.6786] Time_left: 6:11:39.192283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 39/216] [Loss: 0.0397 0.0841 -0.6963 0.2227 1.3348] Time_left: 6:09:38.106200\n",
      "[Epoch 4/200] [Batch 40/216] [Loss: 0.2008 0.0889 -0.6967 0.2758 0.6232] Time_left: 6:11:14.298962\n",
      "[Epoch 4/200] [Batch 41/216] [Loss: 0.6480 0.0702 -0.6896 0.2944 0.7288] Time_left: 6:11:56.608799\n",
      "[Epoch 4/200] [Batch 42/216] [Loss: 0.3014 0.0636 -0.7670 0.1601 0.8189] Time_left: 6:08:39.973838\n",
      "[Epoch 4/200] [Batch 43/216] [Loss: 0.1508 0.1007 -0.6713 0.2559 0.5786] Time_left: 6:09:36.865923\n",
      "[Epoch 4/200] [Batch 44/216] [Loss: 0.0821 0.1023 -0.5869 0.3788 0.6042] Time_left: 6:10:02.073883\n",
      "[Epoch 4/200] [Batch 45/216] [Loss: 0.4059 0.0734 -0.7702 0.2022 0.5971] Time_left: 6:14:16.829297\n",
      "[Epoch 4/200] [Batch 46/216] [Loss: 1.4088 0.0867 -0.6762 0.2947 1.4090] Time_left: 6:12:38.979859\n",
      "[Epoch 4/200] [Batch 47/216] [Loss: 0.2240 0.1090 -0.6941 0.2603 0.8068] Time_left: 6:12:30.919538\n",
      "[Epoch 4/200] [Batch 48/216] [Loss: 0.1014 0.0682 -0.7249 0.1627 0.6375] Time_left: 6:09:03.100056\n",
      "[Epoch 4/200] [Batch 49/216] [Loss: 0.4186 0.0685 -0.7511 0.2455 0.9462] Time_left: 6:11:46.207394\n",
      "[Epoch 4/200] [Batch 50/216] [Loss: 0.2210 0.0952 -0.6266 0.3037 0.4063] Time_left: 6:10:37.496902\n",
      "[Epoch 4/200] [Batch 51/216] [Loss: 0.3405 0.0660 -0.6642 0.2401 1.2615] Time_left: 6:10:04.448004\n",
      "[Epoch 4/200] [Batch 52/216] [Loss: 0.3083 0.0903 -0.6854 0.2618 1.7820] Time_left: 6:09:59.668585\n",
      "[Epoch 4/200] [Batch 53/216] [Loss: 0.3178 0.0735 -0.6651 0.3021 0.9840] Time_left: 6:10:10.031108\n",
      "[Epoch 4/200] [Batch 54/216] [Loss: 1.1045 0.0472 -0.7270 0.1370 1.6888] Time_left: 6:05:04.147890\n",
      "[Epoch 4/200] [Batch 55/216] [Loss: 0.5144 0.1243 -0.6184 0.4089 0.8785] Time_left: 6:16:38.846841\n",
      "[Epoch 4/200] [Batch 56/216] [Loss: 0.2510 0.1111 -0.6671 0.3287 0.3737] Time_left: 6:07:34.790630\n",
      "[Epoch 4/200] [Batch 57/216] [Loss: 0.2454 0.0938 -0.7001 0.2688 1.2100] Time_left: 6:13:31.255704\n",
      "[Epoch 4/200] [Batch 58/216] [Loss: 0.2560 0.1019 -0.6696 0.2573 0.6223] Time_left: 6:05:13.808651\n",
      "[Epoch 4/200] [Batch 59/216] [Loss: 0.3110 0.0856 -0.6815 0.2341 1.4553] Time_left: 6:12:50.925335\n",
      "[Epoch 4/200] [Batch 60/216] [Loss: 0.4769 0.1006 -0.5743 0.2953 1.2342] Time_left: 6:10:28.266792\n",
      "[Epoch 4/200] [Batch 61/216] [Loss: 0.4691 0.0519 -0.7614 0.1401 1.0719] Time_left: 6:10:02.069420\n",
      "[Epoch 4/200] [Batch 62/216] [Loss: 0.4184 0.0538 -0.7953 0.1606 0.8116] Time_left: 6:09:14.112901\n",
      "[Epoch 4/200] [Batch 63/216] [Loss: 0.5138 0.0636 -0.7518 0.1990 1.6510] Time_left: 6:09:27.064021\n",
      "[Epoch 4/200] [Batch 64/216] [Loss: 0.7745 0.0585 -0.7905 0.2481 1.3909] Time_left: 6:12:34.673698\n",
      "[Epoch 4/200] [Batch 65/216] [Loss: 0.4039 0.0974 -0.6510 0.3522 1.1567] Time_left: 6:09:27.506836\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import argparse\n",
    "import trainer\n",
    "\n",
    "def str2bool(v):\n",
    "    #print(v)\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Unsupported value encountered.')\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # ----------------------------------------\n",
    "    #        Initialize the parameters\n",
    "    # ----------------------------------------\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Pre-train, saving, and loading parameters\n",
    "    parser.add_argument('--save_path', type = str, default = '../models/models_TinyDerainGAN_lr0001_raindrop', help = 'saving path that is a folder')  #often changed\n",
    "    parser.add_argument('--sample_path', type = str, default = '../samples/models_TinyDerainGAN_lr0001_raindrop', help = 'training samples path that is a folder')  #often changed\n",
    "    parser.add_argument('--train_batch_size', type = int, default = 4, help = 'size of the batches')\n",
    "    parser.add_argument('--save_by_epoch', type = int, default = 50, help = 'interval between model checkpoints (by epochs)')\n",
    "    parser.add_argument('--epochs', type = int, default = 200, help = 'number of epochs of training')  #often changed\n",
    "    \n",
    "    parser.add_argument('--lr', type = float, default = 0.0001, help = 'Adam: learning rate')\n",
    "    parser.add_argument('--b1', type = float, default = 0.5, help = 'Adam: decay of first order momentum of gradient')\n",
    "    parser.add_argument('--b2', type = float, default = 0.999, help = 'Adam: decay of second order momentum of gradient')\n",
    "    \n",
    "    #raindrop\n",
    "    parser.add_argument('--baseroot', type = str, default = '../rainy_image_dataset/raindrop/train/', help = 'images baseroot')\n",
    "    \n",
    "    #rain100H\n",
    "    #parser.add_argument('--baseroot', type = str, default = '../rainy_image_dataset/rain100H/train/', help = 'images baseroot')\n",
    "    #parser.add_argument('--epochs', type = int, default = 250, help = 'number of epochs of training')  #often changed\n",
    "    \n",
    "    #Rain1400\n",
    "    #parser.add_argument('--baseroot', type = str, default = '../rainy_image_dataset/Rain1400/train/', help = 'images baseroot')\n",
    "    #parser.add_argument('--epochs', type = int, default = 100, help = 'number of epochs of training')  #often changed\n",
    "    \n",
    "    \n",
    "    parser.add_argument('--save_mode', type = str, default = 'epoch', help = 'saving mode, and by_epoch saving is recommended')\n",
    "    parser.add_argument('--save_by_iter', type = int, default = 100000, help = 'interval between model checkpoints (by iterations)')\n",
    "    parser.add_argument('--load_gname', type = str, default = '', help = 'load the pre-trained generator model with certain epoch')\n",
    "    parser.add_argument('--load_dname', type = str, default = '', help = 'load the pre-trained discriminator model with certain epoch')\n",
    "    # GPU parameters\n",
    "    parser.add_argument('--no_gpu', type = str2bool, default = False, help = 'True for CPU')\n",
    "    parser.add_argument('--multi_gpu', type = str2bool, default = False, help = 'True for more than 1 GPU')\n",
    "    #parser.add_argument('--multi_gpu', type = bool, default = False, help = 'True for more than 1 GPU')\n",
    "    parser.add_argument('--gpu_ids', type = str, default = '0, 1, 2, 3', help = 'gpu_ids: e.g. 0  0,1  0,1,2  use -1 for CPU')\n",
    "    parser.add_argument('--cudnn_benchmark', type = str2bool, default = True, help = 'True for unchanged input data type')\n",
    "    # Training parameters\n",
    "    #parser.add_argument('--lr', type = float, default = 0.0002, help = 'Adam: learning rate')\n",
    "    parser.add_argument('--weight_decay', type = float, default = 0, help = 'weight decay for optimizer')\n",
    "    parser.add_argument('--lr_decrease_epoch', type = int, default = 50, help = 'lr decrease at certain epoch and its multiple')\n",
    "    parser.add_argument('--num_workers', type = int, default = 1, help = 'number of cpu threads to use during batch generation')\n",
    "    # Initialization parameters\n",
    "    parser.add_argument('--init_type', type = str, default = 'xavier', help = 'initialization type of generator')\n",
    "    parser.add_argument('--init_gain', type = float, default = 0.02, help = 'initialization gain of generator')\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--crop_size', type = int, default = 256, help = 'single patch size')\n",
    "    parser.add_argument('--geometry_aug', type = str2bool, default = False, help = 'geometry augmentation (scaling)')\n",
    "    parser.add_argument('--angle_aug', type = str2bool, default = False, help = 'geometry augmentation (rotation, flipping)')\n",
    "    parser.add_argument('--scale_min', type = float, default = 1, help = 'min scaling factor')\n",
    "    parser.add_argument('--scale_max', type = float, default = 1, help = 'max scaling factor')\n",
    "    parser.add_argument('--mu', type = int, default = 0, help = 'Gaussian noise mean')\n",
    "    parser.add_argument('--sigma', type = int, default = 30, help = 'Gaussian noise variance: 30 | 50 | 70')\n",
    "    parser.add_argument('--raincover', type = str2bool, default = False, help = 'true for using raincover')  #raincover\n",
    "    parser.add_argument('--raincover_number', type = str2bool, default = 2, help = 'number for raincover')  #raincover\n",
    "    parser.add_argument('--rainaug', type = str2bool, default = False, help = 'true for using rainaug')  #rainmix\n",
    "    \n",
    "    opt = parser.parse_args(args=[])\n",
    "    print(opt)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    #       Choose pre / continue train\n",
    "    # ----------------------------------------\n",
    "    trainer.Pre_train(opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
