{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(angle_aug=False, b1=0.5, b2=0.999, baseroot='./rainy_image_dataset/rain100H/train/', blind_est=True, burst_length=1, channel_att=False, color=True, core_bias=False, crop_size=256, cudnn_benchmark=True, epochs=1, geometry_aug=False, gpu_ids='0, 1, 2, 3', init_gain=0.02, init_type='xavier', kernel_size=[3], load_name='', lr_decrease_epoch=50, lr_g=0.0002, mu=0, multi_gpu=False, no_gpu=False, num_workers=1, rainaug=False, sample_path='./samples', save_by_epoch=10, save_by_iter=100000, save_mode='epoch', save_path='./models/models_k3_d4_ssimloss_SavePredictedKernel', scale_max=1, scale_min=1, sep_conv=False, sigma=30, spatial_att=False, train_batch_size=16, upMode='bilinear', weight_decay=0)\n",
      "initialize network with xavier type\n",
      "Generator is created!\n",
      "pretrained models loaded\n",
      "There are 1 GPUs used\n",
      "The overall number of training images: 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py:2479: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1] [Batch 0/113] [Loss: 0.4276 0.1123] Time_left: 0:07:48.139697\n",
      "[Epoch 1/1] [Batch 1/113] [Loss: 0.4526 0.1134] Time_left: 0:00:14.284519\n",
      "[Epoch 1/1] [Batch 2/113] [Loss: 0.4526 0.1016] Time_left: 0:00:31.607725\n",
      "[Epoch 1/1] [Batch 3/113] [Loss: 0.4865 0.0817] Time_left: 0:00:32.385283\n",
      "[Epoch 1/1] [Batch 4/113] [Loss: 0.4533 0.0807] Time_left: 0:00:33.945712\n",
      "[Epoch 1/1] [Batch 5/113] [Loss: 0.4420 0.1028] Time_left: 0:00:31.402496\n",
      "[Epoch 1/1] [Batch 6/113] [Loss: 0.4243 0.0916] Time_left: 0:00:32.157420\n",
      "[Epoch 1/1] [Batch 7/113] [Loss: 0.4817 0.0729] Time_left: 0:00:31.324521\n",
      "[Epoch 1/1] [Batch 8/113] [Loss: 0.4313 0.0609] Time_left: 0:00:31.068435\n",
      "[Epoch 1/1] [Batch 9/113] [Loss: 0.4625 0.0754] Time_left: 0:00:32.208107\n",
      "[Epoch 1/1] [Batch 10/113] [Loss: 0.4096 0.0689] Time_left: 0:00:29.773315\n",
      "[Epoch 1/1] [Batch 11/113] [Loss: 0.4260 0.0768] Time_left: 0:00:30.358389\n",
      "[Epoch 1/1] [Batch 12/113] [Loss: 0.4340 0.0503] Time_left: 0:00:30.788175\n",
      "[Epoch 1/1] [Batch 13/113] [Loss: 0.4162 0.0409] Time_left: 0:00:29.579997\n",
      "[Epoch 1/1] [Batch 14/113] [Loss: 0.3563 0.0352] Time_left: 0:00:30.371584\n",
      "[Epoch 1/1] [Batch 15/113] [Loss: 0.3391 -0.1733] Time_left: 0:00:30.453828\n",
      "[Epoch 1/1] [Batch 16/113] [Loss: 1.2431 -0.1705] Time_left: 0:00:28.514522\n",
      "[Epoch 1/1] [Batch 17/113] [Loss: 0.2732 -0.2668] Time_left: 0:00:28.591782\n",
      "[Epoch 1/1] [Batch 18/113] [Loss: 0.3875 -0.0768] Time_left: 0:00:28.224370\n",
      "[Epoch 1/1] [Batch 19/113] [Loss: 0.3592 -0.0739] Time_left: 0:00:27.832584\n",
      "[Epoch 1/1] [Batch 20/113] [Loss: 0.3494 -0.0601] Time_left: 0:00:27.417912\n",
      "[Epoch 1/1] [Batch 21/113] [Loss: 0.4163 -0.1366] Time_left: 0:00:28.414205\n",
      "[Epoch 1/1] [Batch 22/113] [Loss: 0.3765 -0.1061] Time_left: 0:00:27.647263\n",
      "[Epoch 1/1] [Batch 23/113] [Loss: 0.3518 -0.1196] Time_left: 0:00:26.418171\n",
      "[Epoch 1/1] [Batch 24/113] [Loss: 0.3671 -0.2042] Time_left: 0:00:25.796756\n",
      "[Epoch 1/1] [Batch 25/113] [Loss: 0.2957 -0.2466] Time_left: 0:00:26.247549\n",
      "[Epoch 1/1] [Batch 26/113] [Loss: 0.2333 -0.2644] Time_left: 0:00:27.286296\n",
      "[Epoch 1/1] [Batch 27/113] [Loss: 0.1576 -0.3845] Time_left: 0:00:24.853388\n",
      "[Epoch 1/1] [Batch 28/113] [Loss: 0.2053 -0.3900] Time_left: 0:00:25.858210\n",
      "[Epoch 1/1] [Batch 29/113] [Loss: 0.2144 -0.3914] Time_left: 0:00:24.780207\n",
      "[Epoch 1/1] [Batch 30/113] [Loss: 0.2348 -0.3887] Time_left: 0:00:25.883754\n",
      "[Epoch 1/1] [Batch 31/113] [Loss: 0.1539 -0.3854] Time_left: 0:00:24.147113\n",
      "[Epoch 1/1] [Batch 32/113] [Loss: 0.1538 -0.4460] Time_left: 0:00:24.195635\n",
      "[Epoch 1/1] [Batch 33/113] [Loss: 0.1522 -0.4247] Time_left: 0:00:25.767097\n",
      "[Epoch 1/1] [Batch 34/113] [Loss: 0.1551 -0.4127] Time_left: 0:00:24.072121\n",
      "[Epoch 1/1] [Batch 35/113] [Loss: 0.1520 -0.4348] Time_left: 0:00:22.063753\n",
      "[Epoch 1/1] [Batch 36/113] [Loss: 0.1514 -0.3879] Time_left: 0:00:23.299569\n",
      "[Epoch 1/1] [Batch 37/113] [Loss: 0.1574 -0.4029] Time_left: 0:00:23.842665\n",
      "[Epoch 1/1] [Batch 38/113] [Loss: 0.1455 -0.3756] Time_left: 0:00:22.171158\n",
      "[Epoch 1/1] [Batch 39/113] [Loss: 0.1435 -0.4580] Time_left: 0:00:21.998355\n",
      "[Epoch 1/1] [Batch 40/113] [Loss: 0.1409 -0.4239] Time_left: 0:00:22.946045\n",
      "[Epoch 1/1] [Batch 41/113] [Loss: 0.1426 -0.3723] Time_left: 0:00:21.405882\n",
      "[Epoch 1/1] [Batch 42/113] [Loss: 0.1469 -0.4194] Time_left: 0:00:21.045675\n",
      "[Epoch 1/1] [Batch 43/113] [Loss: 0.1390 -0.3671] Time_left: 0:00:20.807002\n",
      "[Epoch 1/1] [Batch 44/113] [Loss: 0.1577 -0.3876] Time_left: 0:00:21.335445\n",
      "[Epoch 1/1] [Batch 45/113] [Loss: 0.1671 -0.4239] Time_left: 0:00:20.242168\n",
      "[Epoch 1/1] [Batch 46/113] [Loss: 0.1781 -0.3885] Time_left: 0:00:19.310751\n",
      "[Epoch 1/1] [Batch 47/113] [Loss: 0.1575 -0.4036] Time_left: 0:00:20.260846\n",
      "[Epoch 1/1] [Batch 48/113] [Loss: 0.1377 -0.4104] Time_left: 0:00:19.371494\n",
      "[Epoch 1/1] [Batch 49/113] [Loss: 0.1596 -0.4106] Time_left: 0:00:19.382401\n",
      "[Epoch 1/1] [Batch 50/113] [Loss: 0.1364 -0.4262] Time_left: 0:00:18.301570\n",
      "[Epoch 1/1] [Batch 51/113] [Loss: 0.1389 -0.3965] Time_left: 0:00:18.321121\n",
      "[Epoch 1/1] [Batch 52/113] [Loss: 0.1590 -0.4520] Time_left: 0:00:18.426744\n",
      "[Epoch 1/1] [Batch 53/113] [Loss: 0.1480 -0.3997] Time_left: 0:00:17.940488\n",
      "[Epoch 1/1] [Batch 54/113] [Loss: 0.1464 -0.4096] Time_left: 0:00:18.436769\n",
      "[Epoch 1/1] [Batch 55/113] [Loss: 0.1435 -0.4204] Time_left: 0:00:17.565784\n",
      "[Epoch 1/1] [Batch 56/113] [Loss: 0.1378 -0.4081] Time_left: 0:00:16.936253\n",
      "[Epoch 1/1] [Batch 57/113] [Loss: 0.1436 -0.4478] Time_left: 0:00:17.683008\n",
      "[Epoch 1/1] [Batch 58/113] [Loss: 0.1513 -0.3852] Time_left: 0:00:16.394464\n",
      "[Epoch 1/1] [Batch 59/113] [Loss: 0.1526 -0.4158] Time_left: 0:00:16.178535\n",
      "[Epoch 1/1] [Batch 60/113] [Loss: 0.1378 -0.3938] Time_left: 0:00:15.889522\n",
      "[Epoch 1/1] [Batch 61/113] [Loss: 0.1365 -0.4627] Time_left: 0:00:15.870604\n",
      "[Epoch 1/1] [Batch 62/113] [Loss: 0.1712 -0.3974] Time_left: 0:00:15.594850\n",
      "[Epoch 1/1] [Batch 63/113] [Loss: 0.1713 -0.4206] Time_left: 0:00:14.456582\n",
      "[Epoch 1/1] [Batch 64/113] [Loss: 0.1535 -0.4378] Time_left: 0:00:14.797079\n",
      "[Epoch 1/1] [Batch 65/113] [Loss: 0.1332 -0.4180] Time_left: 0:00:14.972008\n",
      "[Epoch 1/1] [Batch 66/113] [Loss: 0.1495 -0.3865] Time_left: 0:00:14.095908\n",
      "[Epoch 1/1] [Batch 67/113] [Loss: 0.1444 -0.3941] Time_left: 0:00:13.605614\n",
      "[Epoch 1/1] [Batch 68/113] [Loss: 0.1447 -0.4218] Time_left: 0:00:14.273407\n",
      "[Epoch 1/1] [Batch 69/113] [Loss: 0.1436 -0.4390] Time_left: 0:00:13.112235\n",
      "[Epoch 1/1] [Batch 70/113] [Loss: 0.1414 -0.4345] Time_left: 0:00:12.356427\n",
      "[Epoch 1/1] [Batch 71/113] [Loss: 0.1527 -0.4529] Time_left: 0:00:12.540928\n",
      "[Epoch 1/1] [Batch 72/113] [Loss: 0.1516 -0.3664] Time_left: 0:00:12.255013\n",
      "[Epoch 1/1] [Batch 73/113] [Loss: 0.1398 -0.4032] Time_left: 0:00:11.919632\n",
      "[Epoch 1/1] [Batch 74/113] [Loss: 0.1632 -0.4500] Time_left: 0:00:11.975442\n",
      "[Epoch 1/1] [Batch 75/113] [Loss: 0.1352 -0.3893] Time_left: 0:00:11.077810\n",
      "[Epoch 1/1] [Batch 76/113] [Loss: 0.1447 -0.4070] Time_left: 0:00:11.107152\n",
      "[Epoch 1/1] [Batch 77/113] [Loss: 0.1469 -0.4159] Time_left: 0:00:11.572758\n",
      "[Epoch 1/1] [Batch 78/113] [Loss: 0.1455 -0.4398] Time_left: 0:00:10.267800\n",
      "[Epoch 1/1] [Batch 79/113] [Loss: 0.1474 -0.4287] Time_left: 0:00:10.289661\n",
      "[Epoch 1/1] [Batch 80/113] [Loss: 0.1536 -0.4482] Time_left: 0:00:09.878071\n",
      "[Epoch 1/1] [Batch 81/113] [Loss: 0.1454 -0.4401] Time_left: 0:00:09.598503\n",
      "[Epoch 1/1] [Batch 82/113] [Loss: 0.1597 -0.4505] Time_left: 0:00:09.248040\n",
      "[Epoch 1/1] [Batch 83/113] [Loss: 0.1567 -0.4413] Time_left: 0:00:09.581215\n",
      "[Epoch 1/1] [Batch 84/113] [Loss: 0.1452 -0.4491] Time_left: 0:00:08.363971\n",
      "[Epoch 1/1] [Batch 85/113] [Loss: 0.1337 -0.4825] Time_left: 0:00:08.606031\n",
      "[Epoch 1/1] [Batch 86/113] [Loss: 0.1463 -0.4044] Time_left: 0:00:08.036900\n",
      "[Epoch 1/1] [Batch 87/113] [Loss: 0.1465 -0.4497] Time_left: 0:00:07.721199\n",
      "[Epoch 1/1] [Batch 88/113] [Loss: 0.1637 -0.3650] Time_left: 0:00:07.417625\n",
      "[Epoch 1/1] [Batch 89/113] [Loss: 0.1662 -0.3850] Time_left: 0:00:07.302172\n",
      "[Epoch 1/1] [Batch 90/113] [Loss: 0.1489 -0.4112] Time_left: 0:00:07.206945\n",
      "[Epoch 1/1] [Batch 91/113] [Loss: 0.1484 -0.4526] Time_left: 0:00:06.564048\n",
      "[Epoch 1/1] [Batch 92/113] [Loss: 0.1375 -0.4714] Time_left: 0:00:06.385220\n",
      "[Epoch 1/1] [Batch 93/113] [Loss: 0.1468 -0.4559] Time_left: 0:00:05.807843\n",
      "[Epoch 1/1] [Batch 94/113] [Loss: 0.1315 -0.4364] Time_left: 0:00:05.810534\n",
      "[Epoch 1/1] [Batch 95/113] [Loss: 0.1422 -0.4221] Time_left: 0:00:05.501945\n",
      "[Epoch 1/1] [Batch 96/113] [Loss: 0.1438 -0.4354] Time_left: 0:00:05.211419\n",
      "[Epoch 1/1] [Batch 97/113] [Loss: 0.1509 -0.4185] Time_left: 0:00:05.148888\n",
      "[Epoch 1/1] [Batch 98/113] [Loss: 0.1499 -0.4712] Time_left: 0:00:04.489052\n",
      "[Epoch 1/1] [Batch 99/113] [Loss: 0.1314 -0.4540] Time_left: 0:00:04.138092\n",
      "[Epoch 1/1] [Batch 100/113] [Loss: 0.1287 -0.4193] Time_left: 0:00:03.833179\n",
      "[Epoch 1/1] [Batch 101/113] [Loss: 0.1612 -0.4400] Time_left: 0:00:03.820942\n",
      "[Epoch 1/1] [Batch 102/113] [Loss: 0.1294 -0.4418] Time_left: 0:00:03.313634\n",
      "[Epoch 1/1] [Batch 103/113] [Loss: 0.1612 -0.4321] Time_left: 0:00:02.990420\n",
      "[Epoch 1/1] [Batch 104/113] [Loss: 0.1414 -0.4383] Time_left: 0:00:02.848223\n",
      "[Epoch 1/1] [Batch 105/113] [Loss: 0.1438 -0.4047] Time_left: 0:00:02.336262\n",
      "[Epoch 1/1] [Batch 106/113] [Loss: 0.1337 -0.3828] Time_left: 0:00:02.085760\n",
      "[Epoch 1/1] [Batch 107/113] [Loss: 0.1368 -0.4085] Time_left: 0:00:01.806610\n",
      "[Epoch 1/1] [Batch 108/113] [Loss: 0.1526 -0.4156] Time_left: 0:00:01.497604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1] [Batch 109/113] [Loss: 0.1371 -0.4585] Time_left: 0:00:01.233761\n",
      "[Epoch 1/1] [Batch 110/113] [Loss: 0.1477 -0.4230] Time_left: 0:00:00.897461\n",
      "[Epoch 1/1] [Batch 111/113] [Loss: 0.1547 -0.4125] Time_left: 0:00:00.632955\n",
      "[Epoch 1/1] [Batch 112/113] [Loss: 0.1357 -0.4285] Time_left: 0:00:03.505036\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import trainer\n",
    "\n",
    "def str2bool(v):\n",
    "    #print(v)\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Unsupported value encountered.')\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # ----------------------------------------\n",
    "    #        Initialize the parameters\n",
    "    # ----------------------------------------\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Pre-train, saving, and loading parameters\n",
    "    parser.add_argument('--save_path', type = str, default = './models/models_k3_d4_ssimloss_SavePredictedKernel', help = 'saving path that is a folder')  #often changed\n",
    "    parser.add_argument('--sample_path', type = str, default = './samples', help = 'training samples path that is a folder')  #often changed\n",
    "    parser.add_argument('--save_mode', type = str, default = 'epoch', help = 'saving mode, and by_epoch saving is recommended')\n",
    "    parser.add_argument('--save_by_epoch', type = int, default = 10, help = 'interval between model checkpoints (by epochs)')\n",
    "    parser.add_argument('--save_by_iter', type = int, default = 100000, help = 'interval between model checkpoints (by iterations)')\n",
    "    parser.add_argument('--load_name', type = str, default = '', help = 'load the pre-trained model with certain epoch')\n",
    "    # GPU parameters\n",
    "    parser.add_argument('--no_gpu', type = str2bool, default = False, help = 'True for CPU')\n",
    "    parser.add_argument('--multi_gpu', type = str2bool, default = False, help = 'True for more than 1 GPU')\n",
    "    #parser.add_argument('--multi_gpu', type = bool, default = False, help = 'True for more than 1 GPU')\n",
    "    parser.add_argument('--gpu_ids', type = str, default = '0, 1, 2, 3', help = 'gpu_ids: e.g. 0  0,1  0,1,2  use -1 for CPU')\n",
    "    parser.add_argument('--cudnn_benchmark', type = str2bool, default = True, help = 'True for unchanged input data type')\n",
    "    # Training parameters\n",
    "    parser.add_argument('--epochs', type = int, default = 1, help = 'number of epochs of training')  #often changed\n",
    "    parser.add_argument('--train_batch_size', type = int, default = 16, help = 'size of the batches')\n",
    "    parser.add_argument('--lr_g', type = float, default = 0.0002, help = 'Adam: learning rate for G / D')\n",
    "    parser.add_argument('--b1', type = float, default = 0.5, help = 'Adam: decay of first order momentum of gradient')\n",
    "    parser.add_argument('--b2', type = float, default = 0.999, help = 'Adam: decay of second order momentum of gradient')\n",
    "    parser.add_argument('--weight_decay', type = float, default = 0, help = 'weight decay for optimizer')\n",
    "    parser.add_argument('--lr_decrease_epoch', type = int, default = 50, help = 'lr decrease at certain epoch and its multiple')\n",
    "    parser.add_argument('--num_workers', type = int, default = 1, help = 'number of cpu threads to use during batch generation')\n",
    "    # Initialization parameters\n",
    "    parser.add_argument('--color', type = str2bool, default = True, help = 'input type')\n",
    "    parser.add_argument('--burst_length', type = int, default = 1, help = 'number of photos used in burst setting')\n",
    "    parser.add_argument('--blind_est', type = str2bool, default = True, help = 'variance map')\n",
    "    parser.add_argument('--kernel_size', type = str2bool, default = [3], help = 'kernel size')\n",
    "    parser.add_argument('--sep_conv', type = str2bool, default = False, help = 'simple output type')\n",
    "    parser.add_argument('--channel_att', type = str2bool, default = False, help = 'channel wise attention')\n",
    "    parser.add_argument('--spatial_att', type = str2bool, default = False, help = 'spatial wise attention')\n",
    "    parser.add_argument('--upMode', type = str, default = 'bilinear', help = 'upMode')\n",
    "    parser.add_argument('--core_bias', type = str2bool, default = False, help = 'core_bias')\n",
    "    parser.add_argument('--init_type', type = str, default = 'xavier', help = 'initialization type of generator')\n",
    "    parser.add_argument('--init_gain', type = float, default = 0.02, help = 'initialization gain of generator')\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--baseroot', type = str, default = './rainy_image_dataset/rain100H/train/', help = 'images baseroot')\n",
    "    parser.add_argument('--rainaug', type = str2bool, default = False, help = 'true for using rainaug')\n",
    "    parser.add_argument('--crop_size', type = int, default = 256, help = 'single patch size')\n",
    "    parser.add_argument('--geometry_aug', type = str2bool, default = False, help = 'geometry augmentation (scaling)')\n",
    "    parser.add_argument('--angle_aug', type = str2bool, default = False, help = 'geometry augmentation (rotation, flipping)')\n",
    "    parser.add_argument('--scale_min', type = float, default = 1, help = 'min scaling factor')\n",
    "    parser.add_argument('--scale_max', type = float, default = 1, help = 'max scaling factor')\n",
    "    parser.add_argument('--mu', type = int, default = 0, help = 'Gaussian noise mean')\n",
    "    parser.add_argument('--sigma', type = int, default = 30, help = 'Gaussian noise variance: 30 | 50 | 70')\n",
    "    opt = parser.parse_args(args=[])\n",
    "    print(opt)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    print(opt.no_gpu)\n",
    "    print(opt.no_gpu==False)\n",
    "    '''\n",
    "    \n",
    "    ''' \n",
    "    # ----------------------------------------\n",
    "    #        Choose CUDA visible devices\n",
    "    # ----------------------------------------\n",
    "    if opt.multi_gpu == True:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = opt.gpu_ids\n",
    "        print('Multi-GPU mode, %s GPUs are used' % (opt.gpu_ids))\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "        print('Single-GPU mode')\n",
    "    \n",
    "    #os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "    '''\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "    # ----------------------------------------\n",
    "    #       Choose pre / continue train\n",
    "    # ----------------------------------------\n",
    "    trainer.Pre_train(opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
